{"question": "Docker build fails with 'failed to solve with frontend dockerfile.v0: failed to create LLB definition'. How do I fix it?", "solution": "This often indicates a syntax error in the Dockerfile or missing base image. Validate your Dockerfile syntax and ensure the FROM image exists and is accessible. Try rebuilding with `--no-cache` to force a clean build."}
{"question": "Docker container exits immediately after starting. How to keep it running?", "solution": "Docker containers stop when the main process exits. To keep it running, use a foreground process (like `tail -f /dev/null`) or use `docker run -it <image> /bin/bash` for an interactive shell."}
{"question": "Docker daemon not starting: 'Error starting daemon: pid file found, ensure docker is not running'.", "solution": "Remove stale PID files using `sudo rm /var/run/docker.pid` and restart Docker using `sudo systemctl restart docker`."}
{"question": "Cannot connect to Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?", "solution": "Ensure the Docker service is running: `sudo systemctl start docker`. If still failing, verify your user has access to the docker group: `sudo usermod -aG docker $USER` and re-login."}
{"question": "Docker image size too large. How to reduce it?", "solution": "Use a smaller base image like `alpine`, combine RUN commands to reduce layers, clean up package caches, and use multi-stage builds to discard build dependencies."}
{"question": "Docker run fails with 'port already allocated'. How to fix?", "solution": "Another container or process is using the port. Run `docker ps` to find and stop conflicting containers or change the host port mapping using `-p <new_host_port>:<container_port>`."}
{"question": "Docker build fails with 'permission denied' when copying files.", "solution": "Ensure the build context includes correct file permissions and paths. Avoid copying files from outside the build context. Adjust file permissions using `chmod` or Dockerfile USER directives."}
{"question": "Docker Compose up fails with 'network not found'.", "solution": "Run `docker network ls` to verify existing networks. If missing, remove orphaned containers and rebuild: `docker-compose down && docker-compose up --build`."}
{"question": "Docker container cannot access the internet.", "solution": "Check that the Docker bridge network is active: `docker network inspect bridge`. Restart Docker if the bridge is missing. Also ensure host firewall isn’t blocking outbound traffic."}
{"question": "Image pull fails with 'toomanyrequests: rate limit exceeded'.", "solution": "Authenticate with Docker Hub using `docker login`, use a mirror registry, or consider a Docker Hub Pro account to increase pull limits."}
{"question": "Docker volume not persisting data.", "solution": "Ensure you’re using a named volume or host mount. Anonymous volumes are recreated each run. Use `-v mydata:/app/data` instead of `-v /app/data`."}
{"question": "Docker container time not matching host time.", "solution": "Mount the host’s timezone file with `-v /etc/localtime:/etc/localtime:ro` or use the `TZ` environment variable in your container to set the correct timezone."}
{"question": "Docker build context too large causing slow builds.", "solution": "Use a `.dockerignore` file to exclude unnecessary files (node_modules, build artifacts, logs). Keep context minimal for faster builds."}
{"question": "Docker push fails with 'denied: requested access to the resource is denied'.", "solution": "Ensure you’re logged in to the correct registry and have permissions. Use `docker login <registry>` and confirm repository naming matches registry conventions."}
{"question": "Container logs show 'standard_init_linux.go:219: exec user process caused: no such file or directory'.", "solution": "Your entrypoint or CMD may reference a file with Windows line endings. Convert scripts to Unix format using `dos2unix` before building."}
{"question": "Docker network bridge conflicts with host network IP.", "solution": "Edit `/etc/docker/daemon.json` to change the default bridge subnet: `{ \"bip\": \"172.26.0.1/16\" }`, then restart Docker."}
{"question": "Docker-compose service fails with 'service depends on undefined service'.", "solution": "Ensure service names are correctly spelled and indentation is valid in your `docker-compose.yml`. YAML formatting errors often cause this."}
{"question": "Docker build caching not working. Always rebuilding layers.", "solution": "Avoid using dynamic commands like `ADD . /app` early in the Dockerfile. Reorder Dockerfile so static steps occur first, enabling layer caching."}
{"question": "Docker container uses 100% CPU. How to limit it?", "solution": "Use resource constraints with `--cpus` or `--cpuset-cpus` flags, e.g. `docker run --cpus=1 <image>`. Review app processes inside the container using `docker top`."}
{"question": "Docker image fails with 'no space left on device'.", "solution": "Clean up unused images and containers using `docker system prune -a`. Increase disk size or move Docker storage location via `daemon.json` configuration."}
{"question": "Docker login fails with 'error storing credentials - err: exit status 1, out: not implemented'.", "solution": "The credential helper is not supported on your OS. Remove or modify the helper entry in `~/.docker/config.json` or install a valid helper like `docker-credential-pass`."}
{"question": "Docker container can't resolve DNS names.", "solution": "Set DNS servers explicitly with `--dns 8.8.8.8` or configure `/etc/docker/daemon.json` with a valid DNS entry, then restart Docker."}
{"question": "Docker build fails with 'EACCES: permission denied, mkdir'.", "solution": "Ensure build directory permissions allow access to Docker user. Avoid running builds as non-root unless necessary."}
{"question": "Docker Compose fails with version compatibility errors.", "solution": "Upgrade Docker Compose to latest version. Ensure your `version:` field in YAML matches supported schema (e.g., `version: '3.9'`)."}
{"question": "Docker container restarts repeatedly.", "solution": "Check logs with `docker logs <container>`. If restart policy is `always`, fix root cause inside app (e.g., crash) or set `--restart=no` temporarily."}
{"question": "Docker exec gives 'container not running' error.", "solution": "Ensure container is running: `docker ps -a`. Restart it with `docker start -ai <container>` or use `docker logs` to identify crash reason."}
{"question": "Docker Swarm service stuck in Pending state.", "solution": "Check available nodes and resource limits. Use `docker service ps <service>` to see placement constraints and ensure images are accessible on all nodes."}
{"question": "Docker logs command not showing any output.", "solution": "Verify the container is still running. If logs driver is changed, set it to `json-file` or `local`. Use `docker inspect` to check log driver configuration."}
{"question": "Dockerfile COPY command fails with 'file not found' though file exists.", "solution": "Ensure paths are relative to the build context. Files outside the build directory cannot be copied. Double-check capitalization on case-sensitive systems."}
{"question": "Docker container can't write to mounted volume.", "solution": "The host directory may have restrictive permissions. Adjust ownership using `chown` or mount with appropriate user options."}
{"question": "Docker Compose build fails with 'unknown flag --mount'.", "solution": "You’re using old Compose version. Update to Docker Compose v2 or newer where BuildKit `--mount` is supported."}
{"question": "Docker container cannot reach another container by name.", "solution": "Ensure both containers are on the same user-defined network. Connect them using `docker network connect` or define shared network in Compose."}
{"question": "Docker container fails with 'exec format error'.", "solution": "The image was built for a different architecture (e.g., arm64 vs amd64). Use the correct platform flag: `--platform linux/amd64` during build or run."}
{"question": "Docker pull hangs indefinitely.", "solution": "Try using `--network host` to bypass proxy issues or configure proxy variables in Docker daemon settings. Check for firewall restrictions."}
{"question": "Docker build fails with 'Get https://registry-1.docker.io/v2/: net/http: request canceled'.", "solution": "Network connectivity or proxy misconfiguration. Configure Docker daemon proxy via `/etc/systemd/system/docker.service.d/http-proxy.conf`."}
{"question": "Docker logs show 'cgroup: cannot find cgroup mount destination'.", "solution": "Ensure cgroups are enabled on the host. For WSL2, enable systemd support or upgrade to a version that supports cgroups v2."}
{"question": "Docker container date/time incorrect in Kubernetes.", "solution": "Sync node clocks using NTP. Containers inherit node time; ensure node time is correct and not drifting."}
{"question": "Docker build fails on CI/CD with 'no space left on device'.", "solution": "Clean Docker cache in CI pipeline using `docker system prune -af`. Configure ephemeral runners with larger disks."}
{"question": "Docker push to private registry fails with SSL error.", "solution": "If using a self-signed cert, add it to Docker’s trusted certificates directory (`/etc/docker/certs.d/<registry>/ca.crt`) and restart Docker."}
{"question": "Docker image fails with 'Segmentation fault (core dumped)'.", "solution": "Likely binary incompatibility. Ensure libraries match container architecture and glibc versions. Rebuild image on same architecture as runtime."}
{"question": "Docker Compose up fails with 'Bind for 0.0.0.0:80 failed: port is already allocated'.", "solution": "Stop existing services occupying port 80 using `sudo lsof -i:80` or change port mapping in docker-compose.yml."}
{"question": "Docker container can't connect to host service.", "solution": "Use host gateway alias: `--add-host=host.docker.internal:host-gateway` or access host IP directly from container."}
{"question": "Docker build stuck at 'Sending build context'.", "solution": "Your build context is large. Use `.dockerignore` to exclude unnecessary files or move Dockerfile closer to relevant source directory."}
{"question": "Docker logs show 'OCI runtime create failed: container_linux.go:380: starting container process caused'.", "solution": "Check your ENTRYPOINT or CMD. Invalid executable or missing permissions can cause this. Ensure correct shebang line in scripts."}
{"question": "Dockerfile FROM private registry image fails with authentication error.", "solution": "Create a `~/.docker/config.json` with credentials or use `--build-arg` to pass registry credentials securely during build."}
{"question": "Docker service memory limit not applied in Compose.", "solution": "Compose v3 requires deploying to Swarm mode for `deploy.resources` limits. For local Compose, use `mem_limit` under the service definition."}
{"question": "Docker build fails with 'error creating overlay mount'.", "solution": "File system may be full or overlay driver misconfigured. Clear unused containers and verify overlayfs support in kernel."}
{"question": "Docker container not stopping with Ctrl+C.", "solution": "Foreground process might not handle SIGTERM. Use `--init` flag to include tini as init process to properly handle signals."}
{"question": "Docker Compose down not removing networks.", "solution": "Use `docker-compose down --remove-orphans --volumes --rmi all` to ensure full cleanup of networks, volumes, and images."}
{"question": "Docker inspect shows wrong IP address in Kubernetes pod.", "solution": "When running under Kubernetes, Docker's IP isn’t pod IP. Use `kubectl get pod -o wide` for correct pod networking details."}
{"question": "Docker build using BuildKit fails with 'failed to compute cache key: failed to walk'. How to fix?", "solution": "BuildKit has trouble with large contexts or symlinks. Exclude problematic directories via `.dockerignore` and disable BuildKit temporarily with `DOCKER_BUILDKIT=0` to verify the root cause."}
{"question": "Docker multi-stage build fails when copying artifacts between stages.", "solution": "Ensure that the intermediate stage has a proper alias like `AS builder` and the COPY command uses `--from=builder`. Also confirm that paths exist in the source stage."}
{"question": "Docker image verification with Notary fails with 'timestamp expired'.", "solution": "Update Notary client and reinitialize trust data. Run `docker trust inspect <image>` and `docker trust signer add` to refresh expired timestamp keys."}
{"question": "Docker swarm node shows 'Node is down' even though it's reachable.", "solution": "The node might have mismatched Swarm tokens or firewall blocking the gossip port (7946). Rejoin the swarm using correct token and ensure ports 2377, 7946, and 4789 are open."}
{"question": "Docker container fails to attach GPU with 'no NVIDIA driver found'.", "solution": "Install NVIDIA Container Toolkit and verify driver version matches host GPU driver. Use `--gpus all` flag and check `nvidia-smi` inside container."}
{"question": "Docker image build reproducibility differs across machines.", "solution": "Ensure deterministic builds by pinning dependency versions, using BuildKit cache mounts, and normalizing timestamps via `SOURCE_DATE_EPOCH` environment variable."}
{"question": "Docker container startup delayed due to DNS resolution timeout.", "solution": "Add `--dns 8.8.8.8` or configure `/etc/docker/daemon.json` with a reliable DNS. Avoid corporate DNS blocking internal traffic."}
{"question": "Docker build ARG variable not persisting between stages.", "solution": "ARG values are scoped per stage. Redefine `ARG` in each stage or convert to ENV if persistence is required."}
{"question": "Docker-compose containers not discovering each other via service name.", "solution": "Ensure they share the same network in Compose. Explicitly define `networks:` section and confirm each service uses the same named network."}
{"question": "Docker container runs but application reports 'read-only file system'.", "solution": "The container or specific mount is read-only. Check `docker inspect` Mounts configuration and remove `:ro` from volume flags or remount writable."}
{"question": "Docker build ARGs ignored when building on CI pipeline.", "solution": "Pass args explicitly with `--build-arg` in the CI build command. Environment variables in pipeline are not automatically forwarded to Docker build context."}
{"question": "Docker image built on Mac fails to run on Linux server with 'exec format error'.", "solution": "Images built on Mac (ARM64) differ from x86 Linux. Specify `--platform linux/amd64` during build or enable `buildx` to produce multi-architecture images."}
{"question": "Docker Compose service depends_on not waiting for healthcheck.", "solution": "Compose `depends_on` only manages start order, not readiness. Add `healthcheck` and use `restart: on-failure` or external wait-for scripts to ensure service readiness."}
{"question": "Docker container crashes with 'Out of memory' though host has free memory.", "solution": "Docker cgroup memory limits might be too restrictive. Increase container memory using `--memory` or check for swap disabled scenarios."}
{"question": "Docker build context corrupted with 'tar: unexpected EOF'.", "solution": "Your context directory has broken symlinks or permission issues. Run `docker build . --no-cache` after fixing permissions or clearing temporary files."}
{"question": "Docker container networking breaks after VPN connection is established.", "solution": "VPNs modify routing tables. Use `--network host` for testing or create a custom bridge network unaffected by VPN routes."}
{"question": "Docker compose deploy to swarm fails with 'invalid mount config for type bind'.", "solution": "Bind mounts in Swarm require absolute host paths. Replace relative paths with full paths and ensure the directory exists on all swarm nodes."}
{"question": "Dockerfile RUN apt-get update fails with 'temporary failure resolving archive.ubuntu.com'.", "solution": "This is a DNS issue inside the build context. Add `--network host` to build command or configure DNS in `daemon.json`."}
{"question": "Docker container startup logs stuck at 'waiting for database connection'.", "solution": "Your app likely starts before DB readiness. Implement retry logic or use Docker healthcheck and depends_on to delay startup."}
{"question": "Docker swarm service fails to deploy with 'no suitable node (resource constraints)'.", "solution": "Increase node resource limits or adjust service constraints in Compose using `deploy.resources.reservations` and labels."}
{"question": "Docker registry garbage collection fails with 'manifest references a missing blob'.", "solution": "Run registry GC with `REGISTRY_STORAGE_DELETE_ENABLED=true` and ensure no ongoing push/pull. Remove orphaned manifest files manually if necessary."}
{"question": "Docker container startup too slow due to many mounted volumes.", "solution": "Minimize number of mounts. Combine mounts where possible or use tmpfs for ephemeral data. Excessive mounts cause overlay driver overhead."}
{"question": "Docker network inspection shows stale containers.", "solution": "Run `docker network prune` to remove unused networks. If network still shows ghosts, restart Docker daemon to refresh overlay cache."}
{"question": "Docker image push to Artifactory fails with 'unauthorized: incorrect credentials'.", "solution": "Ensure credentials are stored in `~/.docker/config.json`. Use `docker login <registry>` and confirm repository permissions match."}
{"question": "Docker build with COPY fails due to file path exceeding 255 characters.", "solution": "Shorten directory names or build context path. Docker uses tar which has filename length limits on some OS filesystems."}
{"question": "Docker container clock drift causes SSL handshake failures.", "solution": "Sync container and host clocks with NTP. Mount `/etc/localtime` and `/etc/timezone` or restart the container to resync system time."}
{"question": "Docker logs show 'write /dev/stdout: no space left on device'.", "solution": "The log driver is full or `/var/lib/docker/containers` partition is full. Use `--log-opt max-size` and `max-file` to limit log rotation."}
{"question": "Docker build using COPY --chown fails on Windows hosts.", "solution": "The `--chown` flag is not supported on Windows file systems. Remove it or build on Linux environment."}
{"question": "Docker build fails with 'no matching manifest for linux/amd64 in the manifest list entries'.", "solution": "Your base image lacks an amd64 manifest. Use `--platform` to specify supported architecture or choose a multi-arch base image."}
{"question": "Docker container fails to bind to IPv6 address.", "solution": "Enable IPv6 in Docker daemon configuration by adding `{ \"ipv6\": true, \"fixed-cidr-v6\": \"2001:db8:1::/64\" }` to `daemon.json`."}
{"question": "Docker container starts but can't connect to host database over localhost.", "solution": "Use `host.docker.internal` instead of `localhost` to access host services from container. Alternatively, use host networking mode."}
{"question": "Docker image signing with cosign fails with 'no matching key found'.", "solution": "Ensure public/private key pair is available and environment variable `COSIGN_KEY` points to correct key. Re-sign using `cosign sign --key <keyfile>`."}
{"question": "Docker system prune removes volumes unexpectedly.", "solution": "Avoid using `--volumes` flag unless intended. Run `docker volume ls` before pruning and use labels to protect critical volumes."}
{"question": "Docker compose build fails after upgrading to Compose V2.", "solution": "Ensure the syntax follows latest Compose V2 schema and remove deprecated keys like `links`. Update references to correct CLI (`docker compose`)."}
{"question": "Docker healthcheck always returns unhealthy even though service works.", "solution": "Healthcheck command may not match container shell. Use `/bin/sh -c` for proper command evaluation and ensure exit codes reflect success (0)."}
{"question": "Docker container uses excessive disk space in /var/lib/docker/overlay2.", "solution": "Clean up dangling images with `docker image prune -a` and consider enabling BuildKit for more efficient layer deduplication."}
{"question": "Docker container fails to resolve internal hostname in multi-network setup.", "solution": "Use service names specific to each network. Containers on different networks require explicit network aliases or links to communicate."}
{"question": "Docker build cache shared across stages causing unexpected artifacts.", "solution": "Use `--no-cache` for fresh builds or define build stages explicitly with different ARG/ENV to prevent cache collision."}
{"question": "Docker service unable to pull image from ECR with 'no basic auth credentials'.", "solution": "Run `aws ecr get-login-password | docker login --username AWS --password-stdin <aws_account>.dkr.ecr.<region>.amazonaws.com` to authenticate."}
{"question": "Docker build using SSH key fails with 'no such file or directory' for /root/.ssh/id_rsa.", "solution": "Use BuildKit SSH forwarding: `docker build --ssh default` and ensure key is loaded in ssh-agent via `ssh-add`."}
{"question": "Docker container I/O latency too high under heavy load.", "solution": "Switch to overlay2 storage driver, enable journaling on host filesystem, and consider using bind mounts for high-performance I/O operations."}
{"question": "Docker Swarm service rolling update stuck at 'preparing'.", "solution": "A node might have old images or insufficient resources. Run `docker service ps` and remove stalled tasks manually to resume deployment."}
{"question": "Docker push fails with 'blob upload invalid'.", "solution": "Registry or proxy corrupted upload session. Clear `/var/lib/docker` registry cache or retry push with `--disable-content-trust`."}
{"question": "Docker build cache not shared across runners in CI/CD.", "solution": "Use BuildKit cache exporter with `--cache-to=type=registry` and `--cache-from` options to share layer cache across builds."}
{"question": "Docker daemon uses high memory after multiple builds.", "solution": "Docker build cache and layer metadata accumulate. Run `docker builder prune -a` regularly to free BuildKit cache memory."}
{"question": "Docker container startup fails due to missing /dev/shm mount.", "solution": "Increase shared memory with `--shm-size=1g` or mount manually: `--mount type=tmpfs,destination=/dev/shm`."}
{"question": "Docker overlay network connectivity breaks after host reboot.", "solution": "Docker daemon may restart before network stack stabilizes. Delay Docker startup or restart Docker service manually after boot."}
{"question": "Docker container running as non-root user can't bind to port 80.", "solution": "Ports below 1024 require root privileges. Change application port or use capability flag `--cap-add=NET_BIND_SERVICE`."}
{"question": "Docker image push fails intermittently in CI pipeline.", "solution": "Likely due to parallel pushes. Serialize push steps or use registry cache. Also verify no rate limiting or unstable network conditions."}
{"question": "Docker compose scale command not updating container environment variables.", "solution": "Scaling existing services doesn’t re-evaluate environment variables. Recreate services using `docker compose up -d --force-recreate`."}
{"question": "Docker file copy inside build ignores hidden files.", "solution": "By default, `.dockerignore` might exclude hidden files. Verify patterns and explicitly include hidden files if required using `!.*`."}
{"question": "Docker container on Windows can't resolve Linux hostnames.", "solution": "Windows Docker Desktop uses a VM. Use `host.docker.internal` or configure internal DNS forwarding to access Linux host resources."}
{"question": "Pod stuck in Pending state in Kubernetes. What could be the reason?", "solution": "Pods remain Pending when no nodes satisfy scheduling constraints. Check taints, node selectors, and resource requests using `kubectl describe pod <pod>`."}
{"question": "Kubernetes pod stuck in CrashLoopBackOff. How to troubleshoot?", "solution": "Check logs using `kubectl logs <pod> -p` to inspect previous crashes. Fix the underlying app error and consider adding readiness/liveness probes to handle startup delays."}
{"question": "Kubernetes node shows 'NotReady' status. What to check first?", "solution": "Inspect kubelet logs with `journalctl -u kubelet`. Ensure networking (CNI) is functional and node certificates are valid. Restart kubelet if necessary."}
{"question": "Kubernetes service not reachable externally using NodePort.", "solution": "Verify service type is NodePort and firewall rules allow traffic. Ensure target pods are Ready and endpoints exist using `kubectl get endpoints <service>`."}
{"question": "Pod cannot resolve DNS names inside Kubernetes.", "solution": "Check CoreDNS pods in `kube-system` namespace. Restart them if needed. Verify kube-dns config and ensure correct cluster DNS IP in `/etc/resolv.conf`."}
{"question": "Deployment rollout stuck at 'ProgressDeadlineExceeded'.", "solution": "Your new pods failed to become ready. Inspect events using `kubectl describe deployment`. Fix readiness probes or image issues before retrying rollout."}
{"question": "Kubernetes pod stuck in 'ContainerCreating'.", "solution": "Check if the image is available and pull secrets are configured. Inspect kubelet logs for CNI or volume mount errors causing delay."}
{"question": "kubectl command returns 'connection refused' to API server.", "solution": "The API server might be down or kubeconfig misconfigured. Check control plane pods (`kubectl get pods -n kube-system`) or verify `~/.kube/config` cluster endpoint."}
{"question": "Pod running but can't access another pod via ClusterIP.", "solution": "Ensure both pods are in the same cluster network and no NetworkPolicy is blocking traffic. Use `kubectl exec` to test connectivity using curl or ping."}
{"question": "Kubernetes ConfigMap changes not reflected in running pods.", "solution": "Pods don’t auto-reload updated ConfigMaps. Restart pods or use projected volumes with `subPath` disabled to reflect dynamic changes."}
{"question": "kubectl get pods shows 'ImagePullBackOff'.", "solution": "Verify image name, tag, and registry credentials. Run `kubectl describe pod` to view image pull errors and check for private registry secret configuration."}
{"question": "PersistentVolumeClaim stuck in Pending state.", "solution": "Check if a matching PersistentVolume exists with compatible storage class and access modes. Inspect StorageClass parameters for dynamic provisioning issues."}
{"question": "Pod terminated with 'OOMKilled' status.", "solution": "Container exceeded memory limits. Increase memory limit in the resource spec or optimize application memory usage."}
{"question": "Pod failing due to 'CrashLoopBackOff: Back-off restarting failed container'.", "solution": "Inspect container logs and events. If startup dependencies fail, add initContainers or modify liveness probe thresholds to allow more startup time."}
{"question": "Service type LoadBalancer stuck without external IP.", "solution": "Ensure cloud controller manager is running and your cluster is integrated with a supported cloud provider (e.g., AWS, GCP, Azure). Check CCM logs."}
{"question": "kubectl apply fails with 'forbidden: User cannot patch resource'.", "solution": "Your user lacks RBAC permissions. Use `kubectl auth can-i patch <resource>` and update ClusterRole or RoleBinding accordingly."}
{"question": "Kubernetes dashboard shows 'Unauthorized'.", "solution": "You need a valid service account token. Retrieve it using `kubectl -n kubernetes-dashboard create token admin-user` and use it to login."}
{"question": "Pods scheduled on specific node never start.", "solution": "Check node taints and ensure pod tolerations match. Inspect kubelet status on the node for runtime or disk space issues."}
{"question": "kubectl logs shows 'error: container <name> is terminated'.", "solution": "Add `-p` flag to fetch previous container logs. If needed, describe the pod for termination reason and restart policy behavior."}
{"question": "Kubernetes HorizontalPodAutoscaler not scaling pods.", "solution": "Ensure metrics-server is deployed and providing CPU/memory metrics. Validate target utilization and HPA configuration with `kubectl get hpa`."}
{"question": "kubectl exec fails with 'unable to upgrade connection: container not found'.", "solution": "The pod may have restarted. Re-run `kubectl get pods` to find the new pod name and ensure the target container name matches."}
{"question": "Pod networking broken after CNI plugin upgrade.", "solution": "CNI binaries might mismatch cluster version. Reinstall or rollback CNI plugin (like Calico, Flannel, or Cilium) and verify `kubectl get pods -n kube-system`."}
{"question": "Node disk pressure warning and pods being evicted.", "solution": "Free disk space or increase node storage. Docker or containerd may have stale images; run `kubectl get nodes` to confirm disk pressure status."}
{"question": "kube-proxy crashlooping in kube-system namespace.", "solution": "Check ConfigMap `kube-proxy` for malformed configuration. Reset it or redeploy daemonset using correct API server and cluster CIDR values."}
{"question": "Kubernetes Ingress not routing traffic.", "solution": "Ensure ingress controller (e.g., NGINX) is deployed. Verify ingress rules and service backend health. Use `kubectl describe ingress` to inspect routing."}
{"question": "Pod stuck in Terminating state for long time.", "solution": "Force delete using `kubectl delete pod <name> --grace-period=0 --force`. Check for finalizers or volume unmount issues in describe output."}
{"question": "kubectl delete namespace stuck in Terminating state.", "solution": "A resource with finalizers prevents deletion. Use `kubectl get namespace <ns> -o json | jq .spec.finalizers` and patch to remove finalizers manually."}
{"question": "Pods fail with 'MountVolume.SetUp failed for volume'.", "solution": "Check PersistentVolume and StorageClass driver compatibility. Inspect kubelet logs for CSI driver errors or missing node permissions."}
{"question": "kubectl rollout undo fails with 'no revision found'.", "solution": "Deployment history not available because previous ReplicaSets were cleaned up. Enable `revisionHistoryLimit` > 0 to retain versions."}
{"question": "Service discovery fails between namespaces.", "solution": "Use fully qualified DNS names like `<service>.<namespace>.svc.cluster.local`. Check if NetworkPolicy blocks cross-namespace communication."}
{"question": "kubelet logs show 'x509: certificate has expired or is not yet valid'.", "solution": "Renew certificates with `kubeadm certs renew all` and restart control plane components. Verify time synchronization across nodes."}
{"question": "kubectl get nodes shows some nodes with 'SchedulingDisabled'.", "solution": "Node is cordoned. Run `kubectl uncordon <node>` to allow scheduling again."}
{"question": "Pods fail with 'too many open files' error.", "solution": "Increase ulimit settings in container spec via securityContext or adjust node OS limits for kubelet and container runtime."}
{"question": "kubectl port-forward fails with 'error upgrading connection'.", "solution": "Port-forward requires `kubectl proxy` permissions and open connection to API server. Check firewall and ensure the pod is in Running state."}
{"question": "Service has endpoints but requests time out.", "solution": "Check network policies and kube-proxy mode. If using IPVS, ensure kernel modules `ip_vs` and `ip_vs_rr` are loaded."}
{"question": "Pod stuck in Init state.", "solution": "Inspect initContainer logs using `kubectl logs <pod> -c <init-container>`. Initialization script or dependency likely failing."}
{"question": "Kubernetes Deployment shows more pods than desired.", "solution": "Previous ReplicaSets might not be cleaned. Reduce `revisionHistoryLimit` or manually delete old ReplicaSets."}
{"question": "kubectl top nodes returns 'metrics not available'.", "solution": "Metrics server not running or misconfigured. Deploy metrics-server and ensure API aggregation layer is enabled in the API server."}
{"question": "Pod reports 'permission denied' when writing to volume.", "solution": "Set correct securityContext with `fsGroup` or adjust volume permissions using initContainer before mounting."}
{"question": "Kubernetes secret not being mounted into pod.", "solution": "Ensure secret exists in same namespace and mount paths are correct. Restart pod if secret was created after pod start."}
{"question": "kubectl get events shows 'FailedMount' repeatedly.", "solution": "Volume driver may not support node zone. Verify StorageClass zone configuration and ensure CSI driver pods are healthy."}
{"question": "Node reports 'kubelet: failed to get cgroup stats for pod'.", "solution": "Cgroups might be corrupted. Restart kubelet and container runtime, or reboot node if metrics system is stuck."}
{"question": "Pods not scaling even after updating replica count.", "solution": "Check Deployment selector labels. If they mismatch template labels, new replicas won’t be created."}
{"question": "kubectl describe pod shows 'Back-off pulling image'.", "solution": "Registry unreachable or DNS misconfigured. Ensure image name correctness and add imagePullSecrets if private registry is used."}
{"question": "CoreDNS pods CrashLoopBackOff after upgrade.", "solution": "Corefile syntax may be outdated. Edit ConfigMap and verify `forward` plugin syntax matches your cluster DNS setup."}
{"question": "kubectl proxy command fails with 'could not get server version'.", "solution": "Check API server health and kubeconfig context. Ensure cluster endpoint URL is reachable from your client machine."}
{"question": "Pod stuck at 'Evicted' status.", "solution": "Node ran out of resources. Use `kubectl describe pod` for eviction reason. Delete and recreate pod once node pressure clears."}
{"question": "Kubernetes ingress returns 404 on all routes.", "solution": "Backend service name or port mismatch in ingress rule. Verify service targetPort and ingress annotation syntax."}
{"question": "DaemonSet pods not running on all nodes.", "solution": "Node selectors, taints, or tolerations may exclude nodes. Inspect DaemonSet events and ensure matchLabels align with node labels."}
{"question": "Kubernetes API server high CPU usage.", "solution": "Excessive watch events or metrics queries. Reduce logging verbosity and ensure metrics scraping intervals are optimized."}
{"question": "kubectl drain node fails with 'cannot evict pod managed by DaemonSet'.", "solution": "Use `--ignore-daemonsets` flag when draining nodes. DaemonSet pods are managed automatically after drain completes."}
{"question":"AKS: Pods can’t pull images from Azure Container Registry (ACR). What’s the fix?","solution":"Grant the AKS node pool’s managed identity AcrPull on the ACR (or link ACR during cluster create). Run: `az role assignment create --assignee <nodepool_MI_id> --role AcrPull --scope <acr_id>`. For legacy SP clusters, `az aks update -n <cluster> -g <rg> --attach-acr <acrName>`."}
{"question":"EKS: New pods stuck in Pending with 'insufficient pods' though nodes have CPU/Memory. Why?","solution":"EKS VPC CNI IP exhaustion. Each pod needs an ENI IP. Increase IPs per node by using larger instance types, enable prefix delegation, or set `WARM_IP_TARGET`. Alternatively, use secondary CIDRs or adjust maxPods with `--max-pods` and CNI config."}
{"question":"AKS: LoadBalancer service never gets a public IP.","solution":"Your cluster uses 'outboundType: userDefinedRouting' or a restricted subnet/NSG. Ensure AKS service principal/managed identity has rights on the public IP and LB resource group. Confirm `service.beta.kubernetes.io/azure-load-balancer-ipv4` annotations and that the node resource group exists and is writable."}
{"question":"EKS: kubectl errors 'You must be logged in to the server (Unauthorized)'.","solution":"Your IAM user/role isn’t mapped in `aws-auth` ConfigMap. Add the ARN to `mapUsers`/`mapRoles`, apply the ConfigMap, and ensure you’re assuming the correct role with `aws sts get-caller-identity`."}
{"question":"AKS: Private cluster; kubectl cannot reach API server from local machine.","solution":"Private AKS exposes API only on VNet. Use a jumpbox/ExpressRoute/VPN/Private Endpoint. Alternatively enable 'publicFQDN' with authorized IP ranges for limited public access."}
{"question":"EKS: AWS Load Balancer Controller (ALB) doesn’t create an ALB for an Ingress.","solution":"Controller IAM permissions or OIDC/IRSA missing. Ensure OIDC provider is set (`eksctl utils associate-iam-oidc-provider`), create IAM policy and service account annotation, and verify IngressClass is `alb` with valid `kubernetes.io/ingress.class: alb` or new `ingressClassName`."}
{"question":"AKS: Cluster Autoscaler not scaling out though pods are Pending.","solution":"Node pool scaling disabled or constraints. Ensure `--cluster-autoscaler-profile` configured, node taints/tolerations align, max node count > current, and pending pods request resources that fit VM size. Check `k8s-cluster-autoscaler` logs in kube-system."}
{"question":"EKS: Cluster Autoscaler logs 'failed to build node group' and doesn’t scale.","solution":"Using unmanaged/self-managed nodes without proper ASG tags. Tag the ASG with `k8s.io/cluster-autoscaler/enabled` and `k8s.io/cluster-autoscaler/<cluster-name>` and provide IAM permissions to describe/scale the ASG."}
{"question":"AKS: Pods can’t resolve external DNS names.","solution":"CoreDNS upstream blocked or VNet DNS override. Update CoreDNS ConfigMap `forward . /etc/resolv.conf` or point to Azure DNS (168.63.129.16). Ensure VNet custom DNS allows recursion and NSG/UDR permits outbound 53/UDP/TCP."}
{"question":"EKS: NodeGroup creation fails with 'AccessDenied' on IAM.","solution":"Node role lacks permissions or you used a restricted service-linked role. Attach `AmazonEKSWorkerNodePolicy`, `AmazonEKS_CNI_Policy`, and `AmazonEC2ContainerRegistryReadOnly` to the node instance role, and ensure the cluster role trusts `eks.amazonaws.com`."}
{"question":"AKS: New node pool join fails; nodes stuck NotReady with CNI errors.","solution":"Subnet out of IPs or Azure CNI overlay misconfigured. Expand subnet or enable Azure CNI Overlay, ensure `podCIDR`/`serviceCIDR` don’t overlap with VNet peering ranges. Verify NSG allows intra-subnet traffic."}
{"question":"EKS: Pods can’t reach Internet though nodes can.","solution":"NAT/Gateway or routing issue. For private subnets, ensure NAT Gateway is attached and route tables for ENI subnets have 0.0.0.0/0 to NAT. Verify security group egress rules and Network ACLs."}
{"question":"AKS: CSI Azure Disk PVC stuck in Pending.","solution":"StorageClass zone/sku mismatch or disk encryption set. Ensure `managed-csi` driver installed, correct `skuName` and `zones` match node pool zones. For encryption-at-host or CMK, match cluster configuration and permissions."}
{"question":"EKS: EBS CSI driver PV attach fails with 'Node not found in AZ'.","solution":"Volume and node AZ mismatch. Ensure StorageClass uses `topology.kubernetes.io/zone` and your node group spans the same AZs. Use zonal StorageClass or a Multi-AZ capable storage like EFS for cross-AZ mounts."}
{"question":"AKS: Azure Files PVC mounts but app gets 'permission denied'.","solution":"Samba permissions and UID/GID mapping. Use `mountOptions` (e.g., `dir_mode`, `file_mode`), set `fsGroup` in Pod securityContext, or use Azure Files NFS with proper POSIX permissions."}
{"question":"EKS: Pods randomly drop connections across nodes.","solution":"Security group for pods or incorrect SG rules with VPC CNI SG-for-Pods feature. Ensure inter-pod SG allows required ports and that `AWS_VPC_K8S_CNI_EXTERNALSNAT` is correct for your NAT design."}
{"question":"AKS: NGINX Ingress Controller returns 502/504 intermittently.","solution":"Backend readiness/health probes or SNAT port exhaustion. Increase `max-connections`, tune `proxy-read-timeout`, enable `tcpReuse`. Consider using Azure NAT Gateway to increase outbound SNAT ports."}
{"question":"EKS: ALB targets remain 'unhealthy'.","solution":"Target type or health check mismatch. If using IP mode, ensure pods are reachable from the ALB subnets, correct security groups, and health checks path/port align with Service `targetPort`."}
{"question":"AKS: Upgrading cluster version fails with 'operation not allowed on agentPool'.","solution":"Node pool has unsupported SKU or max surge invalid. Set `--max-surge` to a valid value, ensure VMSS supports upgrade, and remove deprecated preview features before upgrade."}
{"question":"EKS: kubectl hangs until MFA expires or times out.","solution":"AWS CLI creds expire; update kubeconfig with a role that can be assumed and configure MFA caching. Use `aws eks update-kubeconfig --role-arn ...` and renew sessions prior to using kubectl."}
{"question":"AKS: PodIdentity (AAD Pod Identity) stopped working after upgrade.","solution":"AAD Pod Identity is deprecated; migrate to **Azure AD Workload Identity**. Install the webhook, create a Federated Identity Credential for the service account, and update apps to use token exchange."}
{"question":"EKS: IRSA configured but pods still use node IAM role.","solution":"ServiceAccount missing `eks.amazonaws.com/role-arn` annotation or wrong audiences. Ensure OIDC provider is present, SA annotated with correct role, and the role trust policy allows the service account issuer & namespace."}
{"question":"AKS: Node pool autoscaling stuck at minimum size.","solution":"Scale set API throttling or pending pod constraints. Check Cluster Autoscaler logs for 'NoExpanders' or 'Unschedulable'. Increase `maxCount`, remove restrictive nodeSelectors, and ensure quotas are not exceeded at subscription level."}
{"question":"EKS: Fargate pods can’t pull private images from ECR.","solution":"Fargate profile uses pod IAM role (via IRSA) that needs `ecr:GetAuthorizationToken` and related ECR permissions. Ensure the correct subnets are selected and route to ECR endpoints via NAT or VPC endpoints."}
{"question":"AKS: CoreDNS CrashLoopBackOff after enabling Private DNS zones.","solution":"Loop or blocked upstream. Point CoreDNS forwarders to Azure DNS (168.63.129.16) or the Azure DNS Private Resolver. Avoid forwarding back into the same private zone causing recursion."}
{"question":"EKS: NodeGroup creation via eksctl fails with 'insufficient capacity'.","solution":"The chosen instance type is constrained. Use `--instance-types` with multiple options (e.g., m5,m5a,m5n) and enable capacity-optimized Spot or pick on-demand in available AZs."}
{"question":"AKS: NetworkPolicies not enforced.","solution":"Using kubenet or policy addon disabled. Ensure you’re on Azure CNI (or Azure CNI Overlay) with a supported network policy (Calico/Azure NP) and the policy add-on is enabled."}
{"question":"EKS: Pods Scheduling fails due to PodSecurityPolicy after upgrade.","solution":"PSP is deprecated/removed. Migrate to Pod Security Admission (PSA) or Gatekeeper policies and adjust namespace labels (`pod-security.kubernetes.io/*`)."}
{"question":"AKS: Outbound connections fail intermittently under load.","solution":"SNAT port exhaustion on Standard LB outbound. Attach a NAT Gateway or assign multiple outbound IPs to the LB; reduce per-pod outbound bursts via connection pooling."}
{"question":"EKS: 'cni failed to attach ENI' in aws-node logs.","solution":"IAM policy missing for CNI or subnet lacks free IPs. Attach `AmazonEKS_CNI_Policy`, ensure secondary CIDR/IPAM correct, and verify ENI quotas aren’t exhausted."}
{"question":"AKS: kubectl times out when using Azure AD auth.","solution":"Expired token or context mismatch. Re-login with `az login`, refresh the kubeconfig via `az aks get-credentials --overwrite-existing`, and ensure your AAD group is bound in RBAC."}
{"question":"EKS: Private cluster endpoint; nodes can’t join.","solution":"Control plane endpoint private requires node bootstrap from within VPC. Ensure node subnets can reach the endpoint (via VPC endpoints) and that security groups allow 443 to API endpoint."}
{"question":"AKS: Azure Policy add-on blocks deployments unexpectedly.","solution":"A policy or initiative denies resources (e.g., 'deny elevated privileges'). Review `Gatekeeper` or Azure Policy events and exempt namespaces or update constraints as needed."}
{"question":"EKS: NLB for a LoadBalancer Service doesn’t get a static IP.","solution":"NLB is L4 and uses per-AZ IPs; allocate Elastic IPs via annotations (`service.beta.kubernetes.io/aws-load-balancer-eip-allocations`) or switch to ALB for HTTP(S) with static hostnames."}
{"question":"AKS: Disk attach limit reached on nodes.","solution":"VM SKU has max data disks. Spread pods across nodes, use Azure Files/EFS-like shared storage, or choose VM sizes with higher disk limits."}
{"question":"EKS: Prometheus scraping the API server fails with 403.","solution":"RBAC and endpoint access. Enable control plane logging/metrics, create RBAC allowing metrics scraping, or use `kubelet`/node exporters instead of direct API server scraping."}
{"question":"AKS: Node images outdated causing kubelet mismatch.","solution":"Upgrade node image via `az aks nodepool upgrade --node-image-only` per pool. Then do a full cluster version upgrade to align control plane and nodes."}
{"question":"EKS: Cluster upgrade stuck at 'updating nodegroup'.","solution":"Draining blocked by PDBs or DaemonSets. Temporarily relax PDBs, use `kubectl drain --ignore-daemonsets --delete-emptydir-data`, then resume the nodegroup update."}
{"question":"AKS: Ingress with Application Gateway (AGIC) doesn’t route traffic.","solution":"AGIC identity lacks permissions on the App Gateway or wrong subnet. Assign `Contributor` on the App Gateway resource group, ensure proper `ingressClassName: azure/application-gateway` and health probes succeed."}
{"question":"EKS: aws-iam-authenticator 'x509: certificate signed by unknown authority'.","solution":"Out-of-date CA bundle or clock skew. Update CA certs on client, ensure time sync (NTP), and refresh kubeconfig with `aws eks update-kubeconfig`."}
{"question":"AKS: Pod-to-pod connectivity broken across node pools.","solution":"NSG or UDR blocks traffic between subnets, or different VNets without peering. Ensure NSGs allow intra-subnet and inter-subnet traffic and that VNet peering is configured without 'UseRemoteGateways' conflicts."}
{"question":"EKS: Calico network policy logs not visible.","solution":"AWS VPC CNI by default; Calico policy only works if its dataplane is active. Either enable Calico enforcement (BPF mode with CNI compat) or use AWS Network Policy for VPC CNI where supported."}
{"question":"AKS: CSI Snapshot fails to create VolumeSnapshotContent.","solution":"Install the snapshot CRDs and controller matching your Kubernetes version. Ensure your CSI driver supports snapshots and the `VolumeSnapshotClass` points to it."}
{"question":"EKS: EFS CSI mount stalls at 'permission denied'.","solution":"EFS access point POSIX permissions or SG/NACLs. Allow NFS (2049) between node SGs and EFS mount target SGs, use an Access Point with correct UID/GID, and set pod `fsGroup`."}
{"question":"AKS: HPA not scaling; metrics.k8s.io not available.","solution":"Enable the metrics-server add-on or deploy it manually. Ensure API aggregation is functioning and the metrics-server has `--kubelet-insecure-tls` if necessary in private clusters."}
{"question":"EKS: CoreDNS CrashLoop after enabling stubDomains for on-prem DNS.","solution":"DNS loop or unreachable upstream. Verify VPC resolver rules, ensure conditional forwarders route correctly over VPN/Direct Connect, and reduce query timeouts."}
{"question":"AKS: 'QuotaExceeded' when creating node pool.","solution":"Azure subscription or regional quota reached for VM cores or public IPs. Request quota increases for VM series and IPs, or choose another region/VM size."}
{"question":"EKS: Admission webhook timeouts block deployments.","solution":"Webhook endpoint not reachable from API server (private networking). Place webhooks behind a reachable NLB/ALB, use DNS resolvable name, and set reasonable `timeoutSeconds` and `failurePolicy`."}
{"question":"AKS: Pod identities intermittently fail to get tokens (workload identity).","solution":"Federated identity conditions mismatch. Ensure service account issuer matches the federated credential, subject format `system:serviceaccount:<ns>:<sa>`, and time sync between AKS and AAD."}
{"question":"EKS: 'AccessDenied' when AWS LB Controller manages TargetGroups.","solution":"Controller role missing `elasticloadbalancing:*` permissions. Attach the official AWS policy JSON to the IRSA role and ensure correct tags for TG ownership."}
{"question":"AKS: Outbound to specific SaaS is blocked though general Internet works.","solution":"Firewall/NSG or Azure FW DNAT rules. Add FQDN tags or explicit rules to allow the SaaS endpoints, verify proxy configuration in CoreDNS/Pods, and consider Private Endpoints if supported."}
{"question":"EKS: Pods cannot reach kube-dns intermittently.","solution":"Node-local DNS cache not deployed or SG rules block 53/UDP between pods and CoreDNS. Deploy NodeLocal DNSCache for stability and ensure SG allows DNS traffic."}
{"question":"AKS: 'ImagePullBackOff' for images in another tenant’s ACR.","solution":"Cross-tenant ACR access requires guest permissions or pull through ACR-to-ACR replication. Establish Azure AD B2B or use a shared private link + role assignments for the node identity."}
{"question":"EKS: Bottlerocket node group fails to join cluster.","solution":"Bootstrap settings/AMI mismatch. Use the official Bottlerocket EKS AMI, set correct `bootstrap.sh` settings via user data or config, and ensure IMDS and required IAM policies are enabled."}
{"question":"Kubernetes control plane became unresponsive after etcd compaction. API requests time out. What’s happening?","solution":"etcd compaction removed keys still in watch caches. Restart kube-apiserver to rebuild caches and check etcd health via `etcdctl endpoint health`. If corruption persists, restore etcd from latest snapshot."}
{"question":"After upgrading Kubernetes from 1.26 to 1.28, all CRDs backed by conversion webhooks fail to serve.","solution":"Conversion webhook API version changed or TLS cert expired. Check webhook endpoint health, update API version to `v1`, and rotate serving certs if expired."}
{"question":"Pods across namespaces randomly lose network connectivity for seconds every few hours.","solution":"ARP cache exhaustion or conntrack table overflow. Increase `net.netfilter.nf_conntrack_max` and node sysctl, deploy conntrack cleaner DaemonSet, and monitor network saturation."}
{"question":"After restoring etcd snapshot, cluster boots but no pods are scheduled.","solution":"The scheduler lost lease data in etcd. Delete `kube-scheduler` leases in `kube-system`, restart controller-manager and scheduler to recreate coordination leases."}
{"question":"One node constantly flaps between Ready and NotReady with kubelet log 'cgroup driver mismatch'.","solution":"Container runtime uses systemd while kubelet expects cgroupfs. Align drivers in kubelet config (`cgroupDriver: systemd`) or switch containerd configuration accordingly."}
{"question":"CPU utilization in API server spikes when many CRDs installed.","solution":"List/watch load from CRDs. Enable API priority and fairness, set proper cache size, or move infrequently accessed CRDs to aggregated API servers to isolate load."}
{"question":"All pods with initContainers stuck in Init:0/1 after upgrading to containerd 1.7.","solution":"CRI plugin race condition. Restart containerd, check sandbox creation logs, and ensure cni-plugins binary path matches kubelet config. Upgrade to patched containerd version."}
{"question":"Pods using hostPath volumes start failing after node disk cleanup.","solution":"Garbage collection removed files hostPath depended on. Migrate hostPath usage to PersistentVolumes or bind mounts under controlled directories outside kubelet-managed paths."}
{"question":"etcd leader election thrashes every few seconds causing API latency.","solution":"One etcd node suffers I/O or network latency. Replace slow node, verify same CPU and disk IOPS, check NTP sync across control-plane nodes."}
{"question":"Ingress controller stopped reconciling routes after large configmap changes.","solution":"Ingress controller hit rate limit on Kubernetes API. Increase informer resync period, enable caching, or use external datastore (like Redis) for dynamic config reloads."}
{"question":"Pods continuously evicted due to node 'PIDPressure'.","solution":"Too many short-lived processes. Increase node PID limit (`--pod-max-pids` or `/proc/sys/kernel/pid_max`) or tune app process model to reuse workers instead of spawning per-request processes."}
{"question":"Admission webhook blocks all new pod creations with 500 error.","solution":"Webhook backend unavailable or invalid TLS chain. Check webhook service health, ensure CA bundle matches service cert, and update ValidatingWebhookConfiguration."}
{"question":"After adding Calico BPF mode, DNS requests start failing intermittently.","solution":"Node-local-dns conflicts with Calico BPF policy enforcement. Exclude CoreDNS namespace from BPF dataplane or set `CALICO_IPV4POOL_BPFENABLED=false` temporarily."}
{"question":"Cluster metrics show sudden spike in etcd DB size though no new objects created.","solution":"Leaked lease objects or stale events. Compact etcd manually (`etcdctl compact`) and defragment (`etcdctl defrag`) to reclaim space."}
{"question":"Pods using projected service account tokens cannot reach external APIs.","solution":"Bound ServiceAccount tokens expire fast. Update app to reload tokens dynamically or increase `--service-account-issuer` TTL in kube-apiserver."}
{"question":"kube-controller-manager logs show 'Failed to acquire leader lease'.","solution":"Multiple controllers competing with same identity. Ensure unique `--leader-elect-lease-name` or fix RBAC so only one controller instance accesses the lease resource."}
{"question":"Upgraded CoreDNS from 1.8 to 1.11 and now external DNS queries time out.","solution":"Upstream resolver misconfigured. Edit Corefile to include `forward . /etc/resolv.conf` and verify node-level DNS works. Roll back config if plugin chain changed."}
{"question":"API server requests hang during large ConfigMap update.","solution":"ConfigMap objects exceed size limit causing slow serialization. Move large binary data to a volume or external store, or increase `maxRequestBodyBytes` parameter."}
{"question":"Node reboot causes pods with local storage to crash permanently.","solution":"Ephemeral local PVs lost after reboot. Use StatefulSets with persistent storage or use `local-storage` CSI driver to recreate local PVs bound to nodes."}
{"question":"Network policies suddenly block all traffic after CNI restart.","solution":"CNI cache lost network state. Reapply network policies, ensure the CNI plugin (e.g. Calico) reconciler pod is healthy, and reload iptables/eBPF maps."}
{"question":"Cluster upgrade stuck due to PodDisruptionBudget violations.","solution":"Critical workloads set PDB with `minAvailable=1` and only 1 replica. Temporarily remove or adjust PDB, complete upgrade, and restore later."}
{"question":"Pods with sidecars never terminate, causing job completion delays.","solution":"Sidecar containers keep process alive. Use Kubernetes 'Sidecar container' feature (1.28+) or add preStop hooks and shared termination signals via postStart script."}
{"question":"All kubelet logs show 'certificate expired'.","solution":"Node bootstrap cert rotation failed. Manually delete old certs in `/var/lib/kubelet/pki`, restart kubelet, and approve CSR with `kubectl certificate approve`."}
{"question":"Scheduler logs 'No fit found for pod' even though nodes have resources.","solution":"Pod anti-affinity, topology spread, or taints prevent placement. Inspect pod events, check required labels, and temporarily disable anti-affinity to confirm root cause."}
{"question":"Pods using initContainers that download files over HTTPS fail with 'x509 unknown authority'.","solution":"CA bundle missing. Mount `/etc/ssl/certs` from host or include `ca-certificates` in initContainer image."}
{"question":"Custom controllers using informers cause excessive etcd writes.","solution":"Controller creates unnecessary updates. Use `Patch` instead of `Update`, reduce resync frequency, and debounce reconcile loops to avoid high etcd churn."}
{"question":"Pod sandbox creation fails after installing seccomp profile policies.","solution":"Default seccomp profile blocks syscalls required by container runtime. Adjust seccomp profile or disable via `seccompProfile: type: Unconfined` temporarily."}
{"question":"High API latency after enabling audit logging.","solution":"Synchronous audit backend causing I/O bottleneck. Use buffered webhook backend or asynchronous mode, and set `--audit-batch-max-size` to balance throughput."}
{"question":"kubelet memory usage continuously grows without dropping.","solution":"Image GC or pod metrics leak. Restart kubelet periodically, enable `--housekeeping-interval`, and check cadvisor heap profiles for leaks."}
{"question":"Rolling updates take hours though few pods exist.","solution":"Readiness probes delay rollout due to strict thresholds. Tune `failureThreshold` and probe intervals, or parallelize rollout using `maxUnavailable` in Deployment strategy."}
{"question":"Pods can't resolve custom DNS zones after migration to CoreDNS.","solution":"Missing stubDomain entry in ConfigMap. Add `stubDomains` pointing to custom DNS servers and reload CoreDNS pods."}
{"question":"Webhook-based OPA Gatekeeper blocks all traffic with 'timeout'.","solution":"Gatekeeper audit webhook under load. Increase webhook timeoutSeconds, allocate more replicas, and ensure webhook service DNS resolves correctly inside cluster."}
{"question":"Cluster-autoscaler scales nodes but pending pods still not scheduled.","solution":"Pods require more ephemeral-storage than available. Add ephemeral storage requests/limits or switch node type with larger ephemeral disk."}
{"question":"Pods crash with 'Invalid CrossDeviceLink' during volume mount.","solution":"Containerd snapshotter type incompatible with overlay filesystem. Use `overlayfs` snapshotter or switch to fuse-overlayfs compatible configuration."}
{"question":"Pod logs disappear after restart though logging agent is running.","solution":"Logs stored in ephemeral container filesystem. Configure stdout/stderr log driver to persist or mount hostPath `/var/log/pods` to centralized log collector."}
{"question":"Cluster access from CI/CD fails with 'x509: certificate signed by unknown authority'.","solution":"CA certificate changed post-rotation. Update CI kubeconfig with new cluster CA bundle, or regenerate service account token with correct root CA."}
{"question":"Pods experience 30s startup delays after CNI plugin migration.","solution":"Old IPAM caches remain. Clear `/var/lib/cni` and restart kubelet. Validate new CNI binary path and IPAM plugin configuration for correct version."}
{"question":"etcd disk fills rapidly even after compaction.","solution":"Large number of Events or Leases not garbage-collected. Enable TTL controller, prune expired events, and check for controllers spamming resource updates."}
{"question":"kube-scheduler crashlooping with 'nil pointer dereference'.","solution":"Custom scheduler config malformed. Validate `kubescheduler.config.k8s.io/v1` syntax and remove plugin weights causing invalid config merge."}
{"question":"API server crashes under load with 'too many open files'.","solution":"File descriptor limit too low. Raise `LimitNOFILE` in systemd service for kube-apiserver and adjust ulimit for all control-plane processes."}
{"question":"Kubernetes jobs intermittently stuck in 'Active' with completed pods.","solution":"Job controller race. Enable job controller `ttlSecondsAfterFinished` cleanup, delete finalizers manually, or upgrade to Kubernetes ≥1.25 where bug is fixed."}
{"question":"Pod eviction storms when nodes under IO pressure.","solution":"Enable `NodePressureEviction` tuning via kubelet `--eviction-hard` thresholds. Investigate disk I/O saturation using iostat and node logs."}
{"question":"CRD webhook API degraded after adding new version to conversion chain.","solution":"Conversion webhook fails version negotiation. Ensure `storageVersion` matches served version and conversion strategy supports both v1beta1 and v1."}
{"question":"Pod stuck 'Terminating' because finalizer never removed.","solution":"Custom controller hung or deleted. Manually patch the resource to remove finalizers and investigate controller logs for stuck reconcile loops."}
{"question":"Kubelet reports 'NodeHasNetworkUnavailable'.","solution":"CNI plugin failed initialization. Restart kubelet, ensure `/opt/cni/bin` populated, and network interface created by plugin exists. Inspect `/var/log/cni.log`."}
{"question":"PersistentVolume detachment stuck for terminated pods.","solution":"CSI driver not responding to `NodeUnpublishVolume`. Restart node plugin DaemonSet, ensure `volumeAttachment` objects reconcile, and clear orphaned attachments manually."}
{"question":"Metrics API reports negative CPU usage for pods.","solution":"Metrics-server rounding bug or stale cadvisor data. Restart metrics-server, ensure `--kubelet-preferred-address-types` set to InternalIP, and upgrade to fixed version."}
{"question":"API latency spikes every 5 minutes.","solution":"Controller-manager full resyncs. Reduce resync interval, increase API QPS limits, and check CRDs with heavy informer watches causing periodic load."}
{"question":"Kubernetes audit logs missing for some requests.","solution":"Audit policy misconfigured with exclude rules too broad. Review audit policy YAML and ensure correct stages (`RequestResponse`) and non-blocking backends configured."}
{"question":"Pods on ARM nodes fail image pull with 'manifest not found'.","solution":"Image built for amd64 only. Use multi-arch manifest or specify platform during build (`docker buildx build --platform linux/arm64,linux/amd64`)."}
{"question":"Ingress Controller fails TLS handshake for certain domains.","solution":"Ingress secret missing intermediate CA or mismatch in CN/SAN. Recreate secret with complete certificate chain and confirm domain matches CN/SAN entries."}
{"question":"Node-level kube-proxy dies after enabling IPVS.","solution":"IPVS kernel modules not loaded. Run `modprobe ip_vs` and `ip_vs_rr`. Update kube-proxy ConfigMap to include mode: ipvs and reload daemonset."}
{"question":"A production Kubernetes cluster (1.28) intermittently returns 5xx for public APIs behind an NGINX Ingress. Spikes align with heavy deployments and ConfigMap reloads. You also see elevated latency in kube-apiserver and CoreDNS. How do you isolate the bottleneck and stabilize traffic during control-plane churn?","solution":"Start by separating data-plane from control-plane symptoms. \n\n1) Observe ingress dataplane: Check NGINX Ingress Controller metrics (requests, p50/p90/p99 latency, reload events). If reload storms exist, enable `--enable-dynamic-certificates` and `--update-status-on-shutdown=false`. Consider using a dedicated configuration ConfigMap and setting `worker-shutdown-timeout` for graceful reloads. \n2) CoreDNS: Inspect `kubectl -n kube-system logs deploy/coredns` for timeouts. Enable NodeLocal DNSCache to reduce upstream lookups; verify Corefile plugins (`cache`, `forward`) and ensure `forward . /etc/resolv.conf` or the required upstream resolvers are reachable. \n3) API server pressure: Enable API Priority and Fairness (APF) if not already; tune controller watches that cause large object lists (e.g., CRDs). Use audit logs and apiserver metrics (`apiserver_request_duration_seconds`) to identify expensive endpoints. \n4) Deployment storm mitigation: Roll deployments with `maxUnavailable` > 0 but reasonable; stagger rollouts, and enable HorizontalPodAutoscaler stabilization windows to avoid thrashing. \n5) Ingress config reload strategy: Use NGINX `--election-id` for leader election stability; for massive config changes, switch to canary IngressClass to warm new config before flipping traffic. \n6) Network: Validate ENI/SNAT capacity (cloud) or conntrack limits (`nf_conntrack_max`). \n7) Verification: Run synthetic probes during a canary rollout; confirm p99 stabilizes before full rollout. Combine these to smooth reload-induced jitter and reduce control-plane coupling with the data plane."}
{"question":"A multi-tenant cluster uses Calico in eBPF mode. After enabling strict NetworkPolicies and migrating tenants to separate namespaces, some services randomly become unreachable across namespaces. Packet captures show dropped traffic with no matching deny rules. What’s the systematic approach?","solution":"This pattern often indicates policy ordering, namespace selectors, or eBPF program conflicts. \n\n1) Policy audit: Use `calicoctl get networkpolicy -o yaml` and verify namespaceSelectors resolve to intended namespaces. Check for default-deny in each namespace and confirm `egress` rules for DNS and observability sidecars. \n2) eBPF verification: `calico-node` logs may reveal map sync failures. Ensure kernel supports required eBPF features and that BPF programs were reattached after node upgrades (`bpftool prog show`). \n3) Identity resolution: If you use service accounts or labels in `networkPolicy`, confirm label propagation via admission webhooks; a delayed label change can cause transient drops. \n4) Cross-namespace services: Prefer `namespaceSelector`+`podSelector` combos and ensure FQDN policies or egress allow to kube-dns. \n5) Rollback plan: Temporarily switch Calico to iptables dataplane on a subset of nodes to confirm dataplane issue vs. policy logic. \n6) Observability: Enable Calico flow logs; determine which rule matched the drop. Adjust policies to include necessary `egress`/`ingress` to cluster services, and add explicit allowlists for control-plane DNS/metrics endpoints."}
{"question":"After a control-plane node disk failure, etcd was restored from a snapshot. The cluster came back, but HorizontalPodAutoscalers and Leases behave oddly: some controllers never reacquire leader election and new objects sporadically fail with 'resource version too old'. How do you heal the control plane without full redeploy?","solution":"You're seeing watch cache inconsistencies post-restore. \n\n1) Verify etcd health: `etcdctl endpoint status --write-out=table` and `etcdctl alarm list`. Clear any NO_SPACE or CORRUPT alarms. Run a compaction (`etcdctl compact <rev>`) followed by `etcdctl defrag` to reclaim space. \n2) API server restart loop: Restart kube-apiserver to rebuild in-memory watch caches. Stagger restarts to keep quorum available. \n3) Lease cleanup: List leases in `kube-system` and controller namespaces. If leases are stale, delete them (e.g., `kubectl delete lease -n kube-system kube-scheduler`) so controllers can reacquire leadership. \n4) HPA and metrics chain: Validate metrics-server (`kubectl get apiservice v1beta1.metrics.k8s.io -o yaml` for STATUS). If APIServices show discovery failures, restart metrics-server and aggregation layer. \n5) Admission webhooks: Ensure their endpoints are healthy; stale endpoints can block create/updates. \n6) Post-restore consistency: Run conformance checks (e.g., `sonobuoy`) and verify controllers (scheduler, controller-manager) reconcile loops stabilize (look for reduction in 'resource version too old' warnings)."}
{"question":"A StatefulSet with 50 shards uses local NVMe via the local-static-provisioner. After a kernel update + node reboots, some shards fail to mount with 'device busy' and others mount but show silent data corruption. What’s your recovery and future-proofing plan?","solution":"Local PVs bind pods to specific disks; reboots can leave stale mounts or file system issues. \n\nImmediate recovery: \n1) Quarantine nodes with failing shards: cordon and drain (respecting PDBs). \n2) On each problematic node: unmount stale mounts; check `lsblk`, `mount`, `lsof` to identify processes holding devices. \n3) Run fsck (ext4/xfs_repair) as appropriate. If corruption is severe, restore from the most recent verified backup (consider per-shard snapshots). \n4) Validate udev rules and device naming stability; pin by UUID rather than `/dev/nvmeXnY`. \n\nFuture-proofing: \n1) Use the `local-storage` CSI driver which supports proper node fencing and persistent identity; store a disk identity marker file. \n2) Automate pre-reboot hooks to flush I/O and unmount cleanly; use systemd `Before=shutdown.target`. \n3) Implement shard replication or synchronous quorum (if DB supports it) so a single disk failure does not cause RPO>0. \n4) Periodically run scrubbing and integrity checks; collect SMART data to predict failure."}
{"question":"During a blue/green rollout, two versions of a microservice behind an Istio mesh show intermittent '503 upstream connect error or disconnect/reset before headers'. Only under high RPS, and mostly for HTTP/2. Liveness/readiness probes pass. What’s the end-to-end diagnosis path?","solution":"Mesh + rollout issues often come from connection pool limits, HTTP/2 settings, or slow TLS handshakes. \n\n1) Sidecar (Envoy) metrics: Inspect `cluster.upstream_rq_pending_overflow` and `upstream_cx_active` counters. Increase `maxRequestsPerConnection` or disable HTTP/2 where not needed. \n2) Connection pool tuning: In DestinationRule, set outlier detection and connection pool thresholds. For high RPS with short-lived connections, raise `http2MaxRequests` and `maxConnections`. \n3) mTLS: Verify certificate rotation hasn’t caused brief trust gaps; ensure SDS is healthy and `istiod` is not CPU throttled. \n4) Pod resources: Confirm containers are not CPU throttled; bursts for TLS and HPACK decompression need headroom. \n5) Retry budget: Configure exponential backoff with jitter and failover to same-version subset during surge. \n6) Load test: Reproduce with controlled traffic; compare HTTP/1.1 vs HTTP/2. If HTTP/2 exacerbates the issue, consider disabling H2 between sidecars for this service pair. \n7) Validate probe/Ingress mismatch: NGINX/ALB health may succeed on a non-mesh path while mesh traffic fails; unify health endpoint through mesh for consistency."}
{"question":"A GitOps pipeline (Argo CD) floods the API server. Every sync triggers hundreds of full-list calls for CRDs, causing apiserver p99>1s. RBAC is correct; caching seems ineffective. How do you tame API pressure without losing desired-state guarantees?","solution":"Focus on reducing list/watch intensity and object churn. \n\n1) Argo CD settings: Enable resource exclusions (e.g., Events) and narrow the set of watched namespaces. Use ApplicationSet generators to shard apps across multiple controllers to distribute load. \n2) Informer resync: Increase `--app-resync` interval; enable `--sharding` with `--shard` flags. \n3) Large manifests: Split monolithic Helm charts; avoid embedding large binaries or gigantic ConfigMaps/Secrets. \n4) Server-side apply: Prefer SSA with field managers to reduce patch conflicts. Ensure `--prune` is used judiciously to prevent wholesale DELETE/CREATE churn. \n5) API PF (Priority & Fairness): Define fair-queuing for Argo CD clients to prevent starvation of system controllers. \n6) Observability: Track apiserver metrics by user agent; confirm drops after sharding/exclusions. \n7) Last resort: Introduce dedicated APIServer for aggregated CRDs (API Aggregation) isolating heavy CRDs from core paths."}
{"question":"After migrating from Docker Engine to containerd, several Jobs fail with 'text file busy' during entrypoint replacement. Re-running sometimes works. How do you make image + runtime settings robust against this race?","solution":"This is typically due to overlayfs + concurrent file access during exec. \n\n1) Stop mutating binaries at startup; bake final entrypoints into the image. If you must replace, write to a new path and `exec` it rather than in-place replace. \n2) Use `initContainers` to stage artifacts into an `emptyDir` (medium: Memory if small or default if larger), then point CMD to that immutable copy. \n3) If you wrap shells, ensure `fsGroup`/permissions are set once and avoid chmod/chown on hot code paths. \n4) On containerd, consider `overlayfs` vs `native` snapshotter tradeoffs. If fuse-overlayfs is used (rootless), upgrade to a version with race fixes. \n5) Validate that anti-virus/EDR on nodes isn’t locking files. \n6) Add `terminationGracePeriodSeconds` and retry with backoff for transient locks while you remove mutation from the startup path."}
{"question":"Kubernetes audit logs show a sudden surge of CREATE/UPDATE calls from a custom controller. etcd size explodes, API server CPU pegs, and the controller logs show reconcile loops reacting to their own status updates. How do you break the feedback loop safely?","solution":"The controller is likely updating status/spec in a way that retriggers its watch. \n\n1) Compare resource versions: Ensure you only PATCH the minimal fields and use `If-Match` semantics (resourceVersion) to avoid unnecessary updates. \n2) Split `status` updates: Use the `/status` subresource and avoid touching `metadata`/`spec` during status writes. \n3) Debounce & backoff: Introduce a jittered rate-limit queue; coalesce multiple events before a reconcile. Increase workqueue delay after no-op reconciles. \n4) Idempotency: Make reconcile functions idempotent; diff desired vs observed and only patch when changes exist. \n5) Rollout mitigation: Temporarily scale the controller to 0, reduce the CR volume (delete noise CRs), or pause the GitOps tool. Then deploy the fixed controller and re-enable gradually. \n6) Post-mortem: Add metrics (`reconcile_attempts`, `status_updates`) and alerts for runaway reconcile patterns."}
{"question":"An AKS private cluster uses Azure CNI overlay. After enabling a Private DNS zone and Azure Firewall, pods intermittently fail to resolve external FQDNs; NodeLocal DNSCache is deployed. Where do you focus and what concrete fixes do you apply?","solution":"Overlay makes pod IPs not routable outside; DNS path must be consistent. \n\n1) Path validation: From a pod, `dig +trace` to see where resolution fails. Confirm NodeLocal DNSCache forwards to CoreDNS, which in turn forwards to Azure DNS (168.63.129.16) or the resolver you intend. \n2) Azure Firewall: Allow outbound 53/UDP+TCP from node and firewall rules to resolver. If using FQDN tags, verify the domains. \n3) Private DNS zone linking: Ensure the VNet is linked to the Private DNS zone and that split-horizon doesn’t loop. Avoid forwarding back into the same zone. \n4) CoreDNS: Increase `max_concurrent` and cache TTL. Ensure stubdomains don’t point to resolvers only reachable via blocked UDRs. \n5) NodeLocal DNSCache: Update to latest; set `-localip` and `-upstreamsvc` explicitly. If cache evictions high, grow cache capacity. \n6) Verification: Run steady DNS qps tests; ensure p99 latency is stable and NXDOMAIN rates match expectations."}
{"question":"On EKS with IRSA, a high-throughput uploader pod intermittently gets 403 on S3 PUT even though the role has s3:PutObject. CloudTrail shows AssumeRoleWithWebIdentity failures during bursts. How do you fully bulletproof token exchange?","solution":"IRSA relies on OIDC tokens that may expire or hit throttles. \n\n1) SDK config: Ensure your SDK uses a cached credential provider and retries AssumeRoleWithWebIdentity with exponential backoff. Increase HTTP connection pooling. \n2) Token audiences & clock skew: Confirm the projected service account token’s aud matches IAM role trust policy; fix NTP drift on nodes to prevent early/late token rejection. \n3) Token refresh: Lengthen token rotation window; mount the projected token and ensure the SDK reloads automatically (newer AWS SDKs support file-watching). \n4) Scale-out: If bursts exceed STS throttling, shard workloads across multiple roles or pre-warm connections. Consider larger pod replicas to smooth spikes. \n5) Observability: Emit STS metrics and S3 retry counts; validate drop after adding backoff + connection reuse."}
{"question":"An on-prem cluster upgraded to 1.29 with containerd 1.7. A subset of nodes repeatedly show 'NodeHasDiskPressure' despite ample free space. `du` reveals massive growth under `/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots`. GC seems stuck. What next?","solution":"Containerd snapshot GC can stall if references are leaked. \n\n1) List dangling snapshots: `ctr snapshots ls` and `ctr content ls` to find unreferenced blobs. \n2) Restart sequence: Stop kubelet, then containerd, run `ctr snapshots cleanup`, start containerd, then kubelet. \n3) Check CRI plugin: `containerd-shim` leaks or old pods that never terminated can pin snapshots. Remove dead sandboxes with `crictl rmp` and `crictl rmi` for old images. \n4) Prevent reoccurrence: Enable periodic `containerd` GC via timers; prune unused images using a controlled policy. Ensure logging agents rotate logs so large layers aren’t recreated constantly."}
{"question":"A platform team enforces Pod Security Standards (restricted) plus Gatekeeper policies. After rollout, Jobs and initContainers widely fail with 'permission denied' and 'capability not allowed'. How do you restore function without breaking security posture?","solution":"You need case-by-case exceptions while maintaining baseline. \n\n1) Inventory failures: Collect OPA/Gatekeeper violations via audit; map constraints blocking specific workloads (initContainers often need elevated permissions). \n2) Namespaced exceptions: Label specific namespaces with PSA exemptions or Gatekeeper `excludedNamespaces`. \n3) Fine-grained policies: For workloads requiring NET_BIND_SERVICE or SYS_TIME, define Constraints allowing these capabilities for labeled service accounts only. \n4) Migration: Refactor pods to drop all caps by default and add minimal ones; use ephemeral containers for debug with elevated profiles in a break-glass namespace. \n5) Verification: Add admission tests in CI validating new manifests against the policy set to prevent regressions."}
{"question":"Multiple clusters share a single external etcd for historical reasons. After a network partition, only one cluster recovered; the others show frequent leader re-elections and high latency. How do you de-risk and migrate with minimal downtime?","solution":"Shared etcd is a liability. \n\n1) Stabilize: Increase etcd quorum stability by ensuring low, consistent latency between etcd peers. Remove unhealthy members and add dedicated nodes for each cluster’s etcd (or move to embedded control plane etcd). \n2) Snapshot: Take consistent snapshots for each logical dataset (ideally you already separated). If not separated, you must sequence migrations: stand up per-cluster etcd, restore snapshot filtered to that cluster’s keys (advanced), or rebuild control plane from scratch and re-register nodes. \n3) Cutover: Drain control plane components to new etcd endpoints (update manifests on static pods). \n4) Validate: Run conformance and watch apiserver latencies. \n5) Long term: Never share etcd across clusters; isolate failure domains."}
{"question":"Rolling out Pod Topology Spread Constraints (PTSC) to avoid AZ outages led to scheduling failures for critical Deployments during a regional rebalancing event. How do you keep PTSC benefits while avoiding deadlock?","solution":"PTSC can overconstrain placement. \n\n1) Move from `whenUnsatisfiable: DoNotSchedule` to `ScheduleAnyway` with associated `maxSkew` tuned to your node counts. \n2) Combine with soft anti-affinity and appropriate `tolerations` for tainted nodes to increase options. \n3) Provide surge capacity: Temporarily increase replicas or relax PDBs to allow redistributions. \n4) Add a fallback topology key (`topology.kubernetes.io/zone` -> `kubernetes.io/hostname`) to let the scheduler pack if zones are imbalanced. \n5) Simulate with `cluster-autoscaler` and descheduler in staging to verify no deadlocks under node loss."}
{"question":"Your Helm umbrella chart renders ConfigMaps over 1MB, causing slow apiserver responses and sporadic 'Request entity too large' via ingress. You must keep large static routing tables. What’s your design that avoids degrading the control plane?","solution":"Move bulk data off the API server. \n\n1) Store static routing data in an object store (S3/GCS/Azure Blob) and have initContainers fetch it to a shared `emptyDir`. \n2) If you must keep it in Kubernetes, use a PersistentVolume with read-only projection and a sidecar to sync content from source. \n3) Keep ConfigMaps tiny: only include pointers + checksums for integrity. \n4) Apply gzip compression and segment the data into logical chunks, fetched on demand. \n5) Add liveness probes tied to checksum validation and fallback logic."}
{"question":"During a mass node upgrade, kubelet certificate rotations failed. Nodes rejoined with new identities, but old Node objects linger with taints and finalizers, blocking scheduling. How do you cleanly reconcile?","solution":"You need to reconcile Node objects and CSRs. \n\n1) List stuck Nodes; check their `status.addresses` vs actual host IPs. If obsolete, cordon and delete them with `--force --grace-period=0`. \n2) Clean finalizers: Patch Node resources to remove custom finalizers only after ensuring no controllers rely on them. \n3) CSR approval: Auto-approve bootstrap signer, but enforce policy to auto-deny malformed CSRs. \n4) Reconcile taints: Ensure remaining Nodes have only expected taints; remove installation-time taints if pools are ready. \n5) Audit: Build a rotation playbook that drains, rotates, verifies, then uncordons; automate rollback if CSR approval fails."}
{"question":"KServe model inference pods (GPU-enabled) sporadically die with OOM even though `nvidia-smi` shows free VRAM. Node memory seems fine. Dumps show the process is killed by the kernel OOM killer. Root cause and fixes?","solution":"Likely host RAM fragmentation or pinned memory spikes (CUDA). \n\n1) Monitor `oom_kill` in dmesg; correlate with spike in page cache or pinned memory. CUDA can pin host memory beyond container limits. \n2) Set memory limits and `memorySwap` appropriately; disable host overcommit if needed (`vm.overcommit_memory=2`). \n3) Use `NVIDIA_VISIBLE_DEVICES` and MIG to partition GPU, but also cap CPU to avoid burst allocations. \n4) Tune frameworks to limit data prefetch queues and batch sizes. \n5) Consider `--shm-size` for large tensors; offload temp data to NVMe local scratch to reduce RAM pressure."}
{"question":"A cluster uses ExternalDNS with multiple providers (Route53 + Cloudflare). After adding wildcard records for canary, ExternalDNS started flapping records on every sync due to TTL/ownership conflicts. How do you stabilize multi-provider reconciliation?","solution":"Multi-provider needs careful ownership. \n\n1) Use distinct TXT ownership records per provider (e.g., `external-dns/owner=prod-r53` vs `prod-cf`). Configure separate ExternalDNS deployments, each with `--provider` and `--txt-owner-id` unique. \n2) Normalize TTLs in annotations so reconcile diffs don’t churn. \n3) Scope sources via label selectors and `--domain-filter` so providers don’t overlap the same zones. \n4) Add `--policy upsert-only` where deletion is risky. \n5) Validate that wildcards don’t collide with explicit A/AAAA records; prefer ALIAS/CNAME for canary with deterministic ownership."}
{"question":"After enabling IPVS mode for kube-proxy, some Services with externalTrafficPolicy=Local return 503 on one AZ during scale-out. Nodes in that AZ have ready pods, but ipvsadm shows missing endpoints briefly. How to remedy?","solution":"Endpoint programming lag can cause brief blackholes. \n\n1) Ensure CPU headroom for kube-proxy; increase `--proxy-mode=ipvs` sync periods if too aggressive. \n2) Enable EndpointSlice and reduce slice churn by stable labels. \n3) For externalTrafficPolicy=Local, ensure `externalIPs`/LB health checks target correct NodePort and that your LB uses pod health (or `kube-proxy` health) checks per node. \n4) Consider `topologyKeys` or enabling `GracefulTermination` features that keep endpoints shortly after termination. \n5) Validate conntrack settings so new flows don’t race against stale endpoints."}
{"question":"A multi-cluster failover (east/west) uses Istio locality-aware routing and shared GSLB. During a regional outage, failover succeeded but recovery caused traffic pinning to the recovered region for long. What should be tuned to ensure fast failback without flapping?","solution":"Balance DNS/GSLB TTLs with mesh outlier detection. \n\n1) Reduce GSLB TTL moderately; add health checks with hysteresis so recovered regions need several consecutive passes to re-enter rotation. \n2) Istio: tune outlier detection `interval`, `baseEjectionTime`, and `maxEjectionPercent` so endpoints gradually rejoin. \n3) Warm pools: Pre-scale in recovered region, run synthetic probes so readiness becomes meaningful. \n4) Use canary weight ramp for service subsets (DestinationRule) so traffic trickles back before full switch. \n5) Telemetry: Alert on skewed locality percentages to detect sticky recovery."}
{"question":"Developers complain that `kubectl exec` and `port-forward` frequently fail with 'unable to upgrade connection' in a hardened cluster using strict egress policies and a corporate proxy. How do you enable these features without weakening the perimeter?","solution":"These features are API-server initiated SPDY/HTTP2 tunnels. \n\n1) Allow API server to reach kubelet/pods: open required ports on nodes (usually 10250 for kubelet). NetworkPolicies must allow control-plane CIDRs to pods for exec/port-forward. \n2) If using a proxy, bypass for cluster internal traffic; set NO_PROXY to include service CIDRs, pod CIDRs, and apiserver DNS names. \n3) RBAC: Ensure users have `pods/exec` and `pods/portforward` verbs only for necessary namespaces. \n4) Audit: Log exec/port-forward events; rotate tokens regularly. \n5) Test: Validate using `kubectl auth can-i` and run exec from jumpbox inside VPC to avoid proxy hops."}
{"question":"A cluster leverages KEDA for event-driven scale. During Kafka outages, some ScaledObjects oscillate replicas aggressively, destabilizing consumers on recovery. What’s a design to make scaling resilient to source instability?","solution":"Introduce stabilization and backpressure awareness. \n\n1) Use `cooldownPeriod` and `minReplicaCount` > 0 to keep warm instances. \n2) Configure trigger metadata to avoid hyper-sensitivity (e.g., set `lagThreshold`/aggregation windows). \n3) Add HPA `behavior` with scaleDown stabilization windows. \n4) Apply circuit breakers in applications to avoid thrash on broker bounce. \n5) Consider buffering (e.g., dead letter or backoff topics) so scale matches sustainable consumption, not instantaneous lag spikes."}
{"question":"Istio sidecars increase p99 latency by ~20ms for gRPC calls only in nodes with high context switches. CPU not pegged. Perf shows time in kernel networking stack. What would you try?","solution":"Likely kernel + Envoy + gRPC interaction. \n\n1) Pin sidecar CPU with guaranteed QoS or dedicated cpuset to reduce context switch overhead. \n2) Enable `SO_REUSEPORT` listener sharding; increase Envoy worker threads to match cores. \n3) Try disabling TCP segmentation offload (TSO)/generic receive offload (GRO) only for a test; sometimes NIC/virt drivers exacerbate latency. \n4) For gRPC, evaluate `h2c` in-cluster to avoid TLS overhead where acceptable; otherwise enable session resumption and tune `initialWindowSize`. \n5) Update kernel and Envoy to versions with gRPC HTTP/2 performance fixes."}
{"question":"A `kubectl apply` of many CRs fails due to webhook timeouts. Webhook service is up, but endpoints are spread across namespaces and use a mesh ingress for mTLS. How do you ensure reliable webhook admission at scale?","solution":"Admission webhooks must be reachable from the API server even during mesh/ingress disturbances. \n\n1) Host the webhook service on a stable in-cluster Service with clusterIP and skip mesh sidecar (annotation to opt-out) to reduce path complexity. \n2) Pin replicas across zones with PTSC and avoid HPA scaling to zero. \n3) Set `timeoutSeconds` conservatively (1–5s) and `failurePolicy: Ignore` for non-critical validations. \n4) Ensure the CA bundle in the webhook config matches the service’s serving cert; rotate proactively. \n5) Create a canary webhook with sampled admission to test upgrades before global rollout."}
{"question":"Your descheduler evicts pods per policy to improve bin-packing, but during business hours it occasionally triggers cascading reschedules that hit PDBs and cause traffic dips. How to keep the benefits without customer impact?","solution":"Time-box and scope the descheduler. \n\n1) Run descheduler only in off-peak windows via CronJob. \n2) Limit policies to `RemoveDuplicates` and moderate `LowNodeUtilization` thresholds; exclude critical namespaces. \n3) Honor PDBs strictly; simulate with `dryRun` and `evictLocalStoragePods=false`. \n4) Cap simultaneous evictions and add a guard on per-namespace eviction rate. \n5) Monitor latency/availability SLOs during runs; abort if breach."}
{"question":"A team uses ephemeral containers for production debugging. After enabling, you notice secrets occasionally exposed in debug shells. How do you keep this tool while preventing data exfiltration?","solution":"Ephemeral containers should be gated. \n\n1) RBAC: Restrict `ephemeralcontainers` subresource to a small SRE group; all actions audited. \n2) PSP/PSA/Gatekeeper: enforce non-root, drop all capabilities, read-only rootfs, and deny mounts. No network or only loopback if possible. \n3) Secret redaction: Inject a shell profile that masks env vars; block `/var/run/secrets/kubernetes.io/serviceaccount` mounts. \n4) Session recording: Enable tty logging via audit and centralize session logs. \n5) Operational playbook: ephemeral containers allowed only in diagnosed namespaces; cleanup hooks kill them after TTL."}
{"question":"Large nodes (64 cores, 512GB) show degraded pod start times. Profiling reveals kubelet spent time managing cgroups and image pulls. How can you regain fast startups?","solution":"Scale nodes are great but can hurt cold-start. \n\n1) Pre-pull hot images via DaemonSet on rollout; use `crane`/`ctr` with registry cache to avoid cold pulls. \n2) Tune kubelet: increase parallel image pulls (`--image-pull-progress-deadline`), raise `--pods-per-core` appropriately, and ensure systemd cgroup driver is used consistently. \n3) Reduce init tasks: minimize initContainers and heavy shell logic; offload to baked images. \n4) Storage: place containerd root on fast NVMe; ensure no I/O contention with logs. \n5) Networking: pre-create CNI cache; upgrade to CNI versions with faster IPAM."}
{"question":"Multi-arch workloads (arm64 + amd64) on EKS sometimes pull the wrong arch image manifest leading to 'exec format error'. The manifests are multi-arch. What’s the root cause and hardening steps?","solution":"Mismatch can be due to platform negotiation bugs or local `--platform` overrides. \n\n1) Ensure node’s containerd has correct `SystemdCgroup=true` and reports the right `Runtime.GOARCH`. \n2) In Helm charts/Manifests avoid setting `image:tag@sha256:...` with a digest not matching the node arch; instead use per-arch digests or tags. \n3) Use `nodeSelector`/`affinity` to constrain ARM pods to ARM nodes and AMD pods to AMD nodes. \n4) Validate via admission webhook that image manifests include the node’s architecture. \n5) Build with `buildx` and verify manifest list contains expected variants."}
{"question":"Your cluster-wide rate limiter (Envoy rate limit service) uses Redis. During a Redis failover, the proxy started allowing all traffic (fail-open) causing backend overload. How do you design a safe-degraded mode?","solution":"Introduce layered protection. \n\n1) Set per-route local rate limits in Envoy as a fallback, with conservative defaults. \n2) Configure fail-closed for critical routes if SLO demands it, returning 429 instead of hammering backends. \n3) Use a Redis cluster with quorum and health checks; keep latency budgets for remote calls. \n4) Emit overload signals to Kubernetes HPA/PodAutoscaler to temporarily scale services. \n5) Run chaos drills to validate desired behavior under store failures."}
{"question":"A logging agent DaemonSet (Fluent Bit) spikes CPU and drops logs during high churn of short-lived pods. Backpressure causes container log file rotation to fall behind. How do you guarantee lossless (or bounded-loss) logging?","solution":"Design for burst absorption and bounded loss. \n\n1) Use filesystem buffer with quotas and backpressure signals in Fluent Bit; increase `Mem_Buf_Limit` and `storage.max_chunks_up`. \n2) Move container logs to faster disks (NVMe) and enable logrotate with size caps. \n3) Tune retry/backoff to avoid tight loops; enable multiline parsers carefully. \n4) Shard outputs by namespace to parallelize sinks; add a local queue (e.g., Loki Promtail + local WAL). \n5) SLOs: Document acceptable lag, alert when queue depth > threshold; scale DaemonSet by node labels if high-density nodes exist."}
{"question":"A PCI-compliant namespace forbids mounting `emptyDir` with medium=Memory. Your in-house service needs fast scratch space. What’s a compliant alternative?","solution":"Use persistent storage or tmpfs-like volumes under policy. \n\n1) Provision a small fast PVC (NVMe-backed) with strict quotas and encryption. \n2) If CSI supports ephemeral volumes, use `ephemeral` inline PVCs with `ReadWriteOncePod`. \n3) Employ application-level in-memory caches with bounded size and spillover to PVC; tune for GC. \n4) Ensure audit trails for access; wipe on pod termination via preStop hooks."}
{"question":"A large Helm upgrade failed halfway; some CRDs updated, some CustomResources not. Controllers are crashlooping due to version skew. How do you achieve a consistent state without full rollback?","solution":"Repair CRDs and CRs in correct order. \n\n1) Pause controllers by scaling Deployments to 0 to stop bad reconciles. \n2) Apply CRD manifests to target version; verify `storedVersions`. \n3) Run conversion jobs or manual conversions for CRs (export old YAMLs, patch to new schema). \n4) Resume controllers gradually; check leader election and reconcile success. \n5) If necessary, use `kubectl-convert` or custom scripts to re-encode objects in the new version."}
{"question":"Kube-proxy iptables mode shows massive rule chains causing slow updates and packet processing. Migrating to IPVS isn’t immediate. What mitigations are available now?","solution":"Trim churn and simplify chains. \n\n1) Enable EndpointSlice; reduce endpoint updates by stabilizing pod labels. \n2) Increase kube-proxy sync period; batch changes. \n3) Reduce number of NodePorts/LoadBalancer Services; collapse internal services behind a mesh. \n4) Pin frequently updated services to headless and use DNS SRV on clients. \n5) Plan phased migration to IPVS with kernel module pre-load."}
{"question":"Developers depend on `hostNetwork: true` for a latency-sensitive service but it conflicts with NodePorts and monitoring agents. How can you safely provide near-host networking without global side effects?","solution":"Options to isolate ports and still get low latency: \n\n1) Use dedicated nodes (taints/tolerations) for hostNetwork workloads to avoid conflicts. \n2) Bind to specific interfaces/ports; coordinate with kube-proxy reserved ranges. \n3) Evaluate DPDK or SR-IOV for direct NIC access if ultra-low latency is needed. \n4) Add NetworkPolicies to restrict hostNetwork pods' access and egress. \n5) Ensure observability via sidecar agents or eBPF-based collectors that respect hostNetwork."}
{"question":"A cluster’s PDBs protect availability, but during an emergency node drain you must evict pods quickly without violating SLAs. What pre-planning and live steps keep both goals?","solution":"Pre-plan graceful degradation. \n\n1) Design PDBs with realistic `minAvailable`; scale critical services to tolerate at least one node loss per AZ. \n2) Add surge capacity (HPA min > steady state) so drains can proceed. \n3) During emergency, temporarily relax PDBs for targeted services (patch `minAvailable`), drain with `--ignore-daemonsets --delete-emptydir-data`. \n4) After recovery, restore original PDBs and reconcile HPA targets. \n5) Run tabletop exercises to test timings and blast radius."}
{"question":"`kubectl cp` fails against some pods with 'tar not found' or hangs on large files. You need a reliable file transfer method for incident response. What’s the robust approach?","solution":"`kubectl cp` requires `tar` in the container and uses SPDY streams. \n\n1) Include `tar` (or `busybox`) in base images for debug. \n2) Prefer an in-cluster SFTP/HTTPS scratch service; mount it as an initContainer destination for uploads. \n3) Use `kubectl exec -- curl`/`wget` to pull artifacts from a secure endpoint. \n4) For large files, use chunked transfers and validate checksums. \n5) Consider `kubectl debug` with ephemeral containers to temporarily add tooling, then remove."}
{"question":"An admission controller injects sidecars. After a CA rotation, new pods fail admission intermittently with TLS errors. Old pods run fine. How do you rotate webhooks with zero downtime?","solution":"Ensure CA bundle and serving cert rotation is atomic. \n\n1) Deploy new webhook with dual-trust: include both old and new CA in `caBundle` temporarily. \n2) Issue new serving certs for the webhook service; roll the webhook Deployment first, verify readiness. \n3) Update `MutatingWebhookConfiguration`/`ValidatingWebhookConfiguration` to only the new CA after rollout. \n4) Keep replicas >1, and set `failurePolicy: Ignore` for non-critical hooks during rotation window. \n5) Add canary webhook with 1% scope to validate before full switch."}
{"question":"A cluster wide feature gate was enabled via API server flags. Some nodes still behave as if the gate is off, causing divergent behavior in controllers. What is the proper procedure to ensure uniform feature state?","solution":"Feature gates must be consistent across apiserver, controller-manager, scheduler, and kubelets. \n\n1) Audit all component manifests (static pods, systemd units) for the gate. \n2) Roll control plane sequentially, then nodes by pool. \n3) Validate via `/metrics` or component logs that the feature gate is recognized. \n4) If the feature is beta/GA-sensitive, run conformance tests for a sample workload that depends on it. \n5) Document rollback flags to flip off consistently if issues arise."}
{"question":"A workload uses projected service account tokens to call an internal OIDC gateway. After enabling short-lived tokens, intermittent 401s occur on long-lived HTTP/2 connections. What’s the fix?","solution":"Tokens expire but connections persist. \n\n1) Ensure the client library refreshes tokens and renegotiates authorization on long-lived streams; for gRPC, add interceptors to refresh metadata. \n2) Reduce token TTL only if client can handle frequent refresh; otherwise use slightly longer TTL in line with security policy. \n3) On the server, support token revalidation per request/stream and allow grace periods. \n4) Add health checks that fail fast when token refresh fails."}
{"question":"A cluster with SPIRE/SPIFFE identities experiences sudden mTLS failures between services after node replacements. Certificates are valid. Logs show SVID rotation stalls on some nodes. Steps?","solution":"Node attestation and agent rotation likely stuck. \n\n1) Verify SPIRE Agent on nodes has correct join token or attestor config; check clock skew. \n2) Restart agents and server; inspect bundle endpoints and federation. \n3) Ensure the workload API socket is accessible and not blocked by SELinux/AppArmor. \n4) Force reissue SVIDs for affected workloads; validate rotation interval and backoff not overlapping with node drains. \n5) Add alerts for SVID age and rotation latency."}
{"question":"On AKS, you attached a NAT Gateway to increase SNAT ports. Still, sporadic 502s occur under spikes. Connection tracking shows many TIME_WAITs. What else can you tune?","solution":"SNAT is one dimension; ephemeral ports and kernel TCP settings matter. \n\n1) Increase client keep-alive and HTTP connection pooling in apps to reuse ports. \n2) Tune node sysctls: `net.ipv4.ip_local_port_range`, `net.ipv4.tcp_tw_reuse` (careful), and conntrack max. \n3) Move chatty services to private Link/Private Endpoint to reduce egress SNAT needs. \n4) Consider per-pod egress IP (Azure CNI with multi-IP) for distribution. \n5) Observe p99s after changes; ensure no collateral drops."}
{"question":"A multi-tenant platform offers per-namespace ResourceQuotas and LimitRanges. Tenants complain about unexpected OOMKills when concurrency spikes. Metrics show burstable QoS pods get throttled and then OOM. How do you align policy with reality?","solution":"Right-size and classify workloads. \n\n1) For latency-critical services, use Guaranteed QoS by setting `requests==limits`, with headroom in quotas. \n2) Provide dedicated burst pools with higher memory/CPU caps for short windows; enforce via LimitRanges that default requests are not too small. \n3) Educate tenants to set `resources` aligned with observed p95; use Vertical Pod Autoscaler in recommend mode. \n4) Add pod-level circuit breakers to shed load gracefully before OOM."}
{"question":"During cluster restore testing, you find that Secrets re-applied from backups are base64-decoded incorrectly by a homegrown tool, corrupting credentials. How do you make secret restoration safe and verifiable?","solution":"Treat Secrets as opaque and validate integrity. \n\n1) Store encrypted secrets (SOPS/SealedSecrets/External Secrets) instead of raw base64. \n2) Write restore jobs that compare SHA-256 hashes or test decryption before apply. \n3) Use a dry-run apply (`--server-side --dry-run=server`) to validate schemas. \n4) After restore, run connectivity checks (DB login, API tokens). \n5) Version and sign backups; audit toolchain for base64 double-encode/strip issues."}
{"question":"A cluster uses Gatekeeper to block `latest` tags. Developers need controlled exceptions for sandboxes. What’s a policy design that’s robust and auditable?","solution":"Implement allow-by-annotation with scope. \n\n1) ConstraintTemplate checks image tag; deny if `latest` unless namespace has label `policy.k8s.io/allow-latest=true` and object has annotation `policy.k8s.io/exception-ticket=<id>`. \n2) Gatekeeper Audit surfaces exceptions; CI enforces annotation + ticket existence. \n3) Nightly audit report lists all exceptions with age; auto-expire after TTL via a controller. \n4) Education: provide a tool to rewrite tags to digests before prod."}
{"question":"You suspect kube-apiserver memory leak when many watches are open from a service mesh control plane. Memory climbs slowly over days. How to confirm and mitigate without downtime?","solution":"Triangulate leak and reduce pressure. \n\n1) Enable pprof on apiserver, collect heap profiles under load. \n2) Identify the mesh control plane user agents; reduce watch fan-out (shard controllers, increase resync intervals). \n3) Enable APF to isolate their queues. \n4) Increase apiserver replicas and put them behind a local NLB to spread watches. \n5) If leak confirmed in your version, roll a minor upgrade patch with the fix, staggering apiservers to avoid downtime."}
{"question":"Cluster nodes occasionally reboot due to underlying host patches. After reboot, some pods fail because `subPath` volume mounts point to stale inodes. How do you sanitize and prevent recurrence?","solution":"`subPath` is sensitive to path existence/time. \n\n1) On node boot, run a systemd unit to clean stale kubelet `pods/volumes` directories if not mounted. \n2) Avoid dynamic creation under `subPath`; precreate directories via initContainers. \n3) Prefer projected volumes or CSI volumes instead of deep `subPath` trees. \n4) Monitor kubelet logs for `reconstruct volume` errors; alert and cordon nodes with repeated failures."}
{"question":"Your cluster relies on Vertical Pod Autoscaler (Auto) for some services. After upgrading to a new JVM, the VPA over-recommends memory, starving neighbors. What’s your stabilization plan?","solution":"Tame recommendations and isolate noisy apps. \n\n1) Switch to VPA `Recommend` mode temporarily; pin requests via HPA (CPU) and fixed memory until samples stabilize. \n2) Add VPA min/max caps per workload to bound recommendations. \n3) Warm up JVM flags to reduce early allocation spikes; enable `-XX:+UseContainerSupport` and set heap ergonomics. \n4) Use canary workloads with new JVM; only roll to full after VPA proves stable."}
{"question":"Canary analysis (Kayenta) frequently aborts due to metrics gaps when Prometheus undergoes remote write hiccups. How do you keep progressive delivery safe?","solution":"Guard against observability failures. \n\n1) Add SLO for metrics freshness; if freshness fails, pause canaries instead of promoting. \n2) Buffer remote write or deploy local Prometheus shards for canary namespaces to reduce dependency. \n3) Use multiple independent metrics sources if possible. \n4) Decrease metric cardinality for canary to avoid scrape timeouts. \n5) Automate rollback only on bad metrics with good quality flags; otherwise hold state and alert humans."}
{"question":"You run GPU + CPU workloads on the same nodes. Under CPU saturation, GPU jobs slow dramatically despite VRAM headroom. How do you isolate and guarantee GPU throughput?","solution":"CPU starvation throttles GPU feeders. \n\n1) Use node pools dedicated to GPU jobs; taint others. \n2) Pin CPU for GPU pods with Guaranteed QoS and `cpuset`. \n3) Enable `nvidia-cuda-mps` for multi-process sharing and set pod CPU limits to ensure input pipelines keep up. \n4) Separate logging/sidecars to different nodes; keep IRQ balancing sane for NICs feeding data."}
{"question":"A custom CSI driver occasionally deadlocks during NodeUnpublishVolume, leaving volumes stuck. What remediation limits blast radius during an incident?","solution":"Constrain and auto-heal. \n\n1) Add liveness probes with a short failure window; restart nodeplugin pods to break deadlocks. \n2) Use `CSIDriver` object with `fsGroupPolicy` and `attachRequired` configured correctly to avoid unnecessary attach cycles. \n3) Enable `volumeAttachment` garbage collection via controller-manager flags. \n4) Quarantine affected nodes (cordon) and drain volumes gracefully before reschedule."}
{"question":"A microservice uses gRPC streaming and abruptly fails during Node drains even with preStop hooks. Connections drop before load balancer detects unready. How to make drains lossless?","solution":"Sequence conditions and delays. \n\n1) On SIGTERM, immediately fail readiness probe and keep liveness passing; add `terminationGracePeriodSeconds` large enough for stream teardown. \n\n2) Configure load balancer health checks with short interval and `healthy_threshold` low so nodes exit quickly. \n3) Implement server-side graceful shutdown: stop accepting new streams, drain existing with deadlines. \n4) Use connection draining at Ingress/Envoy with `drain_timeout`. \n5) Test end-to-end by draining a single pod under load."}
{"question":"You detect abnormal cluster DNS query volume due to a retry storm from a library bug. CoreDNS CPU spikes, and other services degrade. Fast mitigation?","solution":"Rate-limit and cache aggressively. \n\n1) Patch offending app to back off; meanwhile, add CoreDNS `cache` plugin with increased `max_ttl` and `prefetch`. \n2) Deploy NodeLocal DNSCache to absorb retries locally. \n3) Apply NetworkPolicy to block egress to external DNS from the buggy namespace if queries are external. \n4) Horizontally scale CoreDNS temporarily; after fix, scale down."}
{"question":"A legacy image uses `ENTRYPOINT [\"/bin/sh\",\"-c\",\"exec \"$0\" \"$@\"\", \"myapp\"]` pattern that breaks signal handling and prevents graceful shutdown. Containers linger during rollout. What’s the hardened image entrypoint?","solution":"Use a real init and avoid shell traps. \n\n1) Prefer `ENTRYPOINT [\"tini\",\"--\",\"/usr/local/bin/myapp\"]` or build with a compiled entrypoint that forwards signals. \n2) Drop shell indirection unless needed; if used, set proper trap handling and `set -euo pipefail`. \n3) Verify with `docker run --init` locally and confirm SIGTERM propagation before rollout. \n4) Add readiness gates and reasonable `terminationGracePeriodSeconds`."}
{"question": "On a GKE cluster with Dataplane V2 (eBPF), cross-node pod-to-pod latency spikes intermittently under load, but only for connections using an Istio sidecar. Non-Istio traffic is fine. What's the diagnostic path and fix?", "solution": "The issue is likely eBPF/Istio interaction with the kernel's connection tracking, possibly due to a known bug in older Cilium/GKE versions or kernel. \n\n1) **Diagnosis:** Check `kubectl logs -n kube-system ds/cilium` and kernel logs (`dmesg` on nodes) for eBPF warnings or map limit errors. Use `bpf tool` to inspect map utilization. Compare latency for Istio-enabled vs. non-enabled pods on the same node pairs. \n2) **Istio Tuning:** Disable Istio's TCP metadata exchange (`proxy.cluster.tcpKeepalive` or `PILOT_DISABLE_XDS_TCP_METADATA=true` in Istiod) if using older versions, as this can conflict with eBPF hooks. \n3) **Kernel/Dataplane Upgrade:** Ensure your GKE version and underlying kernel have the latest eBPF-related fixes for Cilium/Dataplane V2 performance. \n4) **Mitigation:** Temporarily disable Dataplane V2 or switch Istio to a non-transparent proxy (not recommended) to confirm eBPF is the source. If confirmed, revert to standard dataplane and plan a phased V2 re-roll after GKE/Cilium update."}
{"question": "A custom Horizontal Pod Autoscaler (HPA) using an external Prometheus metric for queue length fails to scale up during a traffic spike, even though the metric value is clearly high. The HPA status shows 'unknown metric'. How do you troubleshoot the metric flow?", "solution": "The 'unknown metric' status points to a break in the custom metrics pipeline (Application -> Prometheus -> Adapter -> API Server -> HPA). \n\n1) **Prometheus Verification:** Ensure Prometheus is scraping the application correctly and the queue length metric exists and is non-stale via Prometheus UI or direct query. \n2) **Custom Metrics Adapter (CMA) Check:** Verify the CMA (e.g., Prometheus Adapter) pod logs for scraping errors or configuration issues. The CMA's ConfigMap must correctly map the Prometheus query (e.g., `rate(app_queue_length[1m])`) to the Kubernetes API metric name (`my_queue_length`). \n3) **API Service Inspection:** Run `kubectl get apiservice v1beta1.custom.metrics.k8s.io -o yaml` (or v1 depending on cluster version). Ensure the APIService is healthy and points to the CMA service. \n4) **Direct Metric Query:** Use `kubectl get --raw '/apis/custom.metrics.k8s.io/v1beta1/namespaces/<ns>/pods/*/*'` to query the custom metric API directly. If the metric is not returned or the resource version is old, the CMA is the bottleneck. \n5) **Fix:** Correct the regex/naming in the CMA ConfigMap and verify the metric name in the HPA spec matches the CMA's exposed name exactly."}
{"question": "After migrating an EBS-backed StatefulSet volume from one AZ to another (by creating a new PV/PVC), the pod in the new AZ fails to start with 'Permission Denied' during volume mount, even though the original pod's securityContext was not changed.", "solution": "This is likely due to an UID/GID mismatch between the securityContext and the file system on the new volume, a common issue when volumes are moved without preserving context, especially with the EBS CSI driver. \n\n1) **Diagnosis:** Run `kubectl describe pod <failing-pod>` to check mount errors. Use `kubectl debug` or `docker run -it --volume <host-path>:/mnt busybox ls -ld /mnt` on the node to inspect the actual UID/GID of the root directory on the new EBS volume. \n2) **SecurityContext Review:** Verify the StatefulSet's `securityContext` and `volumeClaimTemplates` for `fsGroup`. The `fsGroup` is what Kubernetes attempts to apply to the volume. \n3) **CSI Driver Check:** Ensure the StorageClass used by the PVC has `volumeBindingMode: WaitForFirstConsumer` (if using topology-aware volume provisioning) and that the CSI driver is running on the target node. \n4) **Fix (Immediate):** If the file system is owned by a different UID/GID (e.g., root or a system user), either manually fix permissions with an `initContainer` that runs `chown` (risky for large volumes) or set a matching `fsGroup` and `fsGroupChangePolicy: Always` in the pod spec. The `fsGroupChangePolicy` ensures Kubernetes corrects permissions on the new volume."}
{"question": "A `kubectl delete namespace <ns>` is stuck in 'Terminating'. You've checked for finalizers on the namespace itself, but the output is clean. The namespace contains many Pods and Services.", "solution": "The namespace has objects with unremoved finalizers, but the finalizers are on the child objects (Pods, PVs, Custom Resources), not the namespace itself, or a terminating webhook is blocking. \n\n1) **Identify Finalizer Offenders:** Use `kubectl api-resources --namespaced=true -o name | xargs -n 1 kubectl get --ignore-not-found --all-namespaces -o json | jq -r '.items[] | select(.metadata.finalizers != null) | select(.metadata.namespace == \"<ns>\") | .kind + \"/\" + .metadata.name'` to list all namespaced resources with finalizers. Common culprits are `PersistentVolumeClaims`, `Ingresses` (if using a cloud controller), and Custom Resources (e.g., Istio, Cert-Manager). \n2) **Webhook Check:** Run `kubectl get validatingwebhookconfigurations -o json | jq '.items[] | select(.webhooks[].namespaceSelector | .matchLabels.\"kubernetes.io/metadata.name\" == \"<ns>\")'`. If a webhook targets the terminating namespace, scale it to 0 or delete the configuration to allow object deletion to proceed. \n3) **Manual Finalizer Removal (Last Resort):** For stuck objects identified in step 1, manually patch the resource to remove the finalizer: `kubectl edit <kind>/<name> -n <ns>` and delete the finalizer entry under `metadata.finalizers`. Be extremely cautious with this step as it bypasses controllers."}
{"question": "After upgrading the cluster to Kubernetes 1.28, all Deployments using `hostPath` volumes with `type: DirectoryOrCreate` fail during creation with a new admission error. This was working fine before the upgrade.", "solution": "Kubernetes 1.28 introduced the removal of PodSecurityPolicy (PSP) and the enforcement of Pod Security Admission (PSA) with stronger defaults, likely the `Restricted` profile being applied to the namespace.\n\n1) **Diagnosis:** Run `kubectl describe pod <failing-pod>` and inspect the events. The error will likely mention a security policy violation related to the `hostPath` volume type, as it is a highly privileged mount and restricted by default PSA policies. \n2) **PSA Status Check:** Use `kubectl get ns -L pod-security.kubernetes.io/enforce` to confirm the namespace is labeled with `enforce: restricted` or `enforce: baseline`. \n3) **Mitigation (Immediate):** If the workload is critical, label the namespace with `pod-security.kubernetes.io/enforce: privileged` (risky) or `pod-security.kubernetes.io/enforce: baseline` (less risky, but still allows some hostPath). \n4) **Long-Term Fix (Recommended):** Refactor the workload to use an ephemeral volume type like `emptyDir` or a CSI volume if the data needs persistence. If `hostPath` is strictly required, use the `hostPath` volume type with a single, specific volume (e.g., for `/var/log` mounts) and implement a Gatekeeper policy to strictly limit the allowed paths."}
{"question": "Pods with a liveness probe configured as a `httpGet` to a sidecar container (e.g., Istio) are repeatedly killed in a `CrashLoopBackOff` loop, even though the main application is healthy and the sidecar is running. The main app does not have a liveness probe.", "solution": "The issue is a mismatch in the liveness probe configuration, where the probe targets a sidecar that exits after initialization or fails the liveness path when the main app is healthy, or the sidecar's process is not the main process of the container. \n\n1) **Diagnosis:** Use `kubectl describe pod <pod>` and check the liveness probe details. Run `kubectl logs <pod> -c <sidecar-container>` to see if the sidecar is logging errors on the health check path or if the sidecar process itself is crashing. \n2) **Probe Target:** A liveness probe on a sidecar that acts as a proxy (like Envoy in Istio) should target the proxy's health endpoint, not the application's. For Istio, this is typically port `15021/healthz/ready`. Ensure the `containerName` field in the probe correctly points to the sidecar. \n3) **Logic Mismatch:** The sidecar's liveness check might depend on the main container's readiness (which is not configured). If the sidecar is not the main process, its container might exit, causing the pod to be killed. \n4) **Fix:** Move the liveness probe to target the **main application container** on its dedicated health endpoint. If the sidecar must be checked, ensure its liveness endpoint truly reflects the pod's overall health and use `initialDelaySeconds` to give the sidecar time to start and connect to the application."}
{"question": "A multi-cluster federation uses a shared Argo CD instance. After adding a new cluster, Argo CD goes into a sustained 'unhealthy' state, and its controller pod's memory usage spikes dramatically.", "solution": "Argo CD's controller is likely overloaded by the volume of resources, especially if the new cluster has many CRDs or unmanaged resources, leading to memory pressure and thrashing. \n\n1) **Diagnosis:** Check the Argo CD controller logs for 'Resource is too large' warnings or frequent garbage collection events. Use `kubectl top pod -n argocd` to confirm the memory usage spike. \n2) **Resource Exclusion:** Identify large or frequently changing resources that don't need continuous syncing (e.g., `events`, specific CRDs like `servicemonitors`). Update the `argocd-cm` ConfigMap to exclude these resources using the `resource.exclusion` field. \n3) **Sharding:** If the resource volume is still too high, enable controller sharding. Set the `controller.replicas` and configure sharding with the `--shard` flag on the Argo CD controller deployment to distribute the load across multiple instances. \n4) **Reduce Resync:** Increase the `--app-resync` interval in the controller deployment args to reduce the frequency of full reconciliation checks. \n5) **Prune Optimization:** Ensure the `resource.inclusions` and `resource.exclusions` are optimized to watch only necessary resources, significantly reducing the API server pressure and memory consumption on the controller."}
{"question": "An EKS private cluster with a dedicated Private Link endpoint for the API server has issues where new nodes fail to join the cluster, showing 'timeout contacting API server' during bootstrap.", "solution": "Node joining requires communication with the API server, and in a private EKS cluster using Private Link, the node's route to the API server, security group, and DNS resolution must be correct.\n\n1) **Diagnosis:** Check the `kubelet` logs on a failing node for connection errors to the EKS endpoint URL. Verify the VPC's route table for the node subnet has a route to the Private Link endpoint service. \n2) **Security Groups:** Ensure the **EKS Cluster Security Group** and the **Node Security Group** allow inbound traffic on port 443 from the node security group itself (or the correct node CIDRs). \n3) **Private DNS Resolution:** The EKS endpoint DNS name must resolve to the Private IP in the VPC. Verify the VPC has **DNS hostnames** and **DNS resolution** enabled, and that the appropriate **Route 53 Resolver** (or VPC's internal DNS) is used for the EKS endpoint's hostname. \n4) **Fix:** If the Private DNS is not working, ensure the EKS cluster setting **PrivateAccess** is enabled and that you are using the correct VPC configuration for the EKS control plane endpoint."}
{"question": "A deployment with a custom startup probe (using `exec`) fails to become ready after an image update. The logs show the probe script is attempting to execute, but the pod never transitions from `Pending` to `Running` (or `ContainerCreating`).", "solution": "If the pod is stuck in `ContainerCreating`, the issue is before the application start, likely a volume mount, CNI, or image pull failure. If it is stuck in `Running` but never `Ready`, the probe logic is the problem. Since the startup probe is executing, the container is likely running. \n\n1) **Diagnosis:** Inspect `kubectl describe pod <pod>` events carefully. Check if the container's exit code is non-zero after the startup probe runs, or if the probe timeout is too short. The startup probe prevents liveness/readiness probes from starting until it succeeds. \n2) **Probe Script Logic:** The `exec` command within the probe must exit with code **0** to signal success. If the script is a shell command, ensure it includes an explicit `exit 0` or that the last command truly exits successfully (e.g., `grep 'ready' /var/log/app.log` without a pipe that masks errors). \n3) **Container Shell:** Verify the `exec` shell is available in the image (e.g., `/bin/sh`). If the script uses features not supported by the default shell, it can fail silently. \n4) **Fix:** Simplify the probe to a basic check (e.g., `cat /tmp/ready`) and ensure the application writes this file only when fully initialized. Increase `failureThreshold` and `periodSeconds` for the startup probe to give the application enough time to start without being killed."}
{"question": "Pods with a dedicated Service Account configured for IRSA (IAM Roles for Service Accounts) on EKS intermittently receive 'expired credentials' errors when accessing AWS services, despite the credentials being less than an hour old.", "solution": "IRSA credentials (projected service account tokens) have a limited TTL. The issue is likely that the application or AWS SDK is not properly refreshing the temporary credentials obtained via the `AssumeRoleWithWebIdentity` call, or the token is expiring mid-session. \n\n1) **Token TTL and Clock Skew:** Ensure node time (NTP sync) is accurate. A slight clock skew can cause the token validation on the STS side to fail or be rejected as 'not yet valid'. \n2) **AWS SDK Version:** Verify the application is using a modern AWS SDK (v2 recommended) that supports automatic renewal of credentials derived from the projected service account token file. Older SDKs might cache the session too long. \n3) **Token Mount:** Confirm the token is mounted correctly at `/var/run/secrets/eks.amazonaws.com/serviceaccount/token` and the application's SDK is configured to look there. The projected token itself is constantly renewed by the kubelet. \n4) **Session Reuse:** For long-lived TCP/HTTP connections, the application might reuse the underlying connection without checking the credential validity. Implement an interceptor or connection handler that forces a credential refresh before making a request when a 401/403 is received. \n5) **Mitigation:** Temporarily increase the projected service account token duration (via `--service-account-token-ttl` in `kube-apiserver` args) while you update the application's SDK or credential handling logic."}
{"question": "After deploying a custom resource definition (CRD) with a large schema and many validating webhooks, API server requests for core Kubernetes resources (like Pods) become noticeably slow, and the API server latency spikes at p99.", "solution": "Large CRDs and numerous webhooks can dramatically increase the API server's workload due to complex validation, object size, and increased watch traffic. \n\n1) **CRD Schema Optimization:** Review the CRD schema. Use the smallest possible data types and remove unnecessary `description` fields, as the whole schema is stored and validated. Use `preserveUnknownFields: false` to force structural schema validation. \n2) **Webhook Performance:** Profile the custom webhooks. They must be very fast. If the webhook is slow, set a short `timeoutSeconds` (e.g., 1-2s) and ensure `failurePolicy: Fail` is only used when strictly necessary; use `Ignore` otherwise. \n3) **API Priority and Fairness (APF):** Configure APF to prioritize core resource requests. Define a specific FlowSchema with low priority for API requests originating from the webhook controller's service account to prevent it from starving core requests. \n4) **Aggregated API Server:** For high-volume CRDs, consider migrating them to an Aggregated API Server (AAS). This isolates the CRD processing load from the core Kubernetes API server. \n5) **Mitigation:** Temporarily disable the most expensive validating webhooks to confirm they are the bottleneck."}
{"question": "A high-performance batch processing Job uses `local-storage` volumes backed by NVMe disks. Intermittently, jobs fail with 'I/O error' or 'filesystem corruption' during heavy write phases. The nodes are not under memory or CPU pressure.", "solution": "This points to a flaw in the `local-storage` provisioning model, kernel I/O handling under extreme load, or potentially underlying hardware issues (disk firmware/wear). \n\n1) **Filesystem Check:** After a failure, attempt to run `fsck` or `xfs_repair` on the failed NVMe partition from the host. If errors are found, the initial format or kernel driver is suspect. \n2) **`local-static-provisioner`:** Ensure the provisioner is correctly setting up the volume. Use the `ext4` or `xfs` filesystem with optimal mount options (e.g., `nobarrier`, correct `discard` for TRIM/UNMAP). \n3) **Kernel I/O Tuning:** Check the kernel I/O scheduler (`cat /sys/block/nvme*/queue/scheduler`). Ensure it's set to `none` or `mq-deadline` for NVMe for maximum throughput. Tune the `dirty_ratio` and `dirty_background_ratio` sysctls to prevent massive writebacks that stall the system. \n4) **Job Re-run:** Ensure the Job has a proper `restartPolicy: OnFailure` and that the application handles partial writes and retries gracefully. \n5) **Long-Term:** Migrate to a dedicated **CSI Local Storage Driver** which offers better management, health checking, and support for volume snapshots and resizing compared to the static provisioner."}
{"question": "On an AKS cluster using Azure AD Workload Identity, newly deployed pods fail to acquire tokens from the token exchange endpoint, showing 'invalid client assertion' in the logs, but older pods are working fine.", "solution": "The 'invalid client assertion' error points to an issue with the Service Account's bound identity, likely due to a mismatch between the cluster's OIDC issuer and the Federated Identity Credential in Azure AD. \n\n1) **Diagnosis:** Check the Azure AD Federated Identity Credential for the Managed Identity linked to the Service Account. Verify the `Subject` field exactly matches the expected format: `system:serviceaccount:<namespace>:<serviceaccountname>`. \n2) **OIDC Issuer URL:** Ensure the `AUDIENCE` and `ISSUER` in the Service Account token being presented match the values configured in the Federated Identity Credential. The AKS OIDC issuer URL can change or be misconfigured. \n3) **Clock Skew:** A significant time difference between the AKS control plane (which issues the projected token) and the Azure AD token exchange endpoint can lead to the token being rejected as 'not yet valid'. Check time sync across control plane and nodes. \n4) **Service Account Annotation:** Verify the new pod's Service Account has the correct annotation: `azure.workload.identity/client-id: <Managed Identity Client ID>`. \n5) **Fix:** Recreate the Federated Identity Credential in Azure AD, ensuring the OIDC issuer URL from your AKS cluster is correctly used. If the issue persists, scale the `azure-wi-webhook` to 0, then back up, to force a refresh of its cache."}
{"question": "A critical DaemonSet (e.g., a security agent) uses `hostPath` volumes and runs on all nodes. During a mass cordon/drain operation, the drain gets stuck on these pods, and the `kubectl drain` output shows `DaemonSet-managed pods (use --ignore-daemonsets to proceed)`. You must drain the nodes quickly.", "solution": "DaemonSet pods are managed to run exactly once per node and are by default not evicted during a drain, as they are expected to be rescheduled immediately by the DaemonSet controller. \n\n1) **Immediate Mitigation:** Use `kubectl drain <node> --ignore-daemonsets --delete-emptydir-data`. The `--ignore-daemonsets` flag will skip the DS-managed pods, and the DS controller will automatically spin up the replacement pods on a new, non-cordoned node (or on the same node if the cordon fails before the drain finishes). \n2) **Graceful Mitigation (Preferred):** For future drains, add a PDB (PodDisruptionBudget) for the DaemonSet, even though they are usually ignored by drain logic for DS-managed pods. More importantly, add an annotation to the DaemonSet pod template: `cluster-autoscaler.kubernetes.io/safe-to-evict: \"true\"` (or the equivalent for other autoscalers/draining tools). This allows tools to treat them as safely evictable. \n3) **Long-Term Fix:** If the DaemonSet has critical state, convert it to a different controller type (like a Deployment with a specific `nodeSelector`) or utilize the new **Sidecar Container** feature (Kubernetes 1.28+) for non-essential logging/security agents to decouple their lifecycle from the main app."}
{"question": "After enabling a custom NetworkPolicy that uses the `ipBlock` feature to restrict outbound traffic to a specific external service, the policy starts blocking all egress traffic from the namespace, including DNS resolution to CoreDNS.", "solution": "NetworkPolicy ingress/egress rules are default-deny. When you add an egress rule, you must explicitly allow everything else that was implicitly allowed before, especially DNS resolution. \n\n1) **Diagnosis:** Use a test pod in the namespace and attempt `nslookup kubernetes.default.svc.cluster.local`. If it fails, DNS is blocked. \n2) **CoreDNS IP Block:** CoreDNS is an in-cluster service, not an external IP. However, the policy is likely blocking traffic to the cluster's DNS service IP (usually the service IP of `kube-dns` or `coredns` service in `kube-system`). \n3) **Fix: Add DNS Egress Rule:** Add a specific egress rule to your NetworkPolicy (or a new, dedicated policy for essential services) that explicitly allows UDP and TCP traffic on port 53 to the cluster DNS IP range (Service CIDR) or specifically to the CoreDNS pod IPs. \n\n```yaml\n  - to:\n    - namespaceSelector: {}\n      podSelector:\n        matchLabels:\n          k8s-app: kube-dns # Or coredns label\n    ports:\n      - protocol: UDP\n        port: 53\n      - protocol: TCP\n        port: 53\n```\n4) **Verification:** Use `kubectl exec` into a pod and run `calicoctl policy show` (or CNI equivalent) to verify the rule set includes the essential DNS allow."}
{"question": "A Prometheus-Kube Prometheus Stack deployment is failing to scrape a large number of targets, specifically those in namespaces with high pod churn. The Prometheus server log shows frequent 'context deadline exceeded' errors for scraping.", "solution": "This is a sign of high API server load (Discovery) or network congestion (Scraping), specifically exacerbated by rapid endpoint/pod churn which forces continuous service discovery updates. \n\n1) **APIServer Pressure:** High churn causes frequent updates to `Endpoints`/`EndpointSlices`. If using Prometheus Operator, enable `shard` feature or increase the `replicationFactor` of the Prometheus server to spread the discovery load. \n2) **Target Scrape Timeout:** Increase the global `scrape_timeout` in the Prometheus configuration, or for specific job targets that are known to be slow. \n3) **Network:** Check if the Prometheus server is being throttled by NetworkPolicy or if the node is experiencing network congestion. Use `kube-proxy` in IPVS mode if possible for faster endpoint updates. \n4) **EndpointSlice Optimization:** Ensure you are using `EndpointSlices` (enabled by default in modern K8s) as they are more efficient than `Endpoints`. \n5) **Mitigation:** Temporarily stop scraping high-churn namespaces or increase the scrape interval for those targets until the churn is stabilized."}
{"question": "You are rolling out a new PodDisruptionBudget (PDB) to a critical StatefulSet. After applying, all subsequent rolling updates to the StatefulSet get stuck, showing the PDB preventing the pod termination.", "solution": "The PDB logic is likely conflicting with the StatefulSet's `updateStrategy` or the number of replicas. PDBs protect against *voluntary* disruption (like rolling updates or drains). \n\n1) **Diagnosis:** Run `kubectl describe pdb <pdb-name>`. Check the `Allowed Disruption` field. If it is 0, the PDB is indeed blocking. \n2) **PDB Misconfiguration:** The PDB's `minAvailable` or `maxUnavailable` field is set too restrictively. If the StatefulSet has 3 replicas, a `minAvailable: 3` PDB will never allow a single pod to terminate, causing the update to halt. \n3) **StatefulSet Strategy:** Ensure the StatefulSet's `spec.updateStrategy.rollingUpdate.partition` is set correctly (or not set, defaulting to 0 for a full rollout). A partition higher than the number of replicas being updated can also stall. \n4) **Fix:** Adjust the PDB: for a 3-replica SS, set `maxUnavailable: 1` or `minAvailable: 2`. This allows one pod to be unavailable during the rolling update. \n5) **PDB Lifecycle:** Consider using a controller or GitOps tool that only applies the PDB *after* the initial deployment is stable, or defines the PDB relative to the number of replicas (e.g., in a Helm chart)."}
{"question": "A Docker build pipeline fails intermittently with 'Error processing tar file: write /var/lib/docker/tmp/...: no space left on device', even though the host machine's primary disk has ample space.", "solution": "This error points to a full volume or partition used by Docker's internal storage driver (usually `/var/lib/docker`), specifically the temporary build cache or the underlying loopback device if using a legacy driver. \n\n1) **Diagnosis:** Check disk usage on the partition containing `/var/lib/docker`. If it's a loopback device (for older setups), check the actual size of the loopback file. Use `df -h /var/lib/docker`. \n2) **BuildKit Cache:** If using BuildKit (recommended), the issue is likely the builder cache. Run `docker builder prune -a` to clear the cache. \n3) **Old Images/Layers:** Prune all dangling images and stopped containers: `docker system prune -a --volumes`. \n4) **Driver Misconfiguration:** If the Docker data root is on a partition with limited space, or if the storage driver (e.g., `overlay2`) has internal limits, the build can fail. \n5) **Fix:** Increase the size of the partition hosting `/var/lib/docker` or configure Docker to use a different data root (by editing `/etc/docker/daemon.json` with the `data-root` option, followed by a daemon restart). Use multi-stage builds to minimize layer size."}
{"question": "Pods running a new application version start up, immediately pass readiness, but fail liveness probes 30 seconds later, showing a 'connection refused' error. The application logs indicate the service is fully operational.", "solution": "This is a race condition where the application's readiness signal is premature, or the liveness probe logic is fundamentally flawed in its timing or target. \n\n1) **Readiness/Liveness Mismatch:** The readiness probe indicates the *server* is accepting connections, but the liveness probe is failing because the *application logic* hasn't initialized yet. \n2) **Probe Type:** If both are HTTP probes, ensure the liveness probe targets a path that confirms *deep* health (e.g., DB connectivity), while readiness targets *basic* health (e.g., process running). \n3) **Liveness Probe Tune:** Increase the `initialDelaySeconds` and `periodSeconds` for the liveness probe. A 30s failure after startup suggests an initialization timeout that the liveness probe hits immediately after the initial delay expires. \n4) **Fix: Readiness Gate:** Implement a proper readiness gate within the application. The application should only start listening on the readiness port (or return 200) once *all* initialization is complete. If using a file-based readiness, ensure the file is only created at the very end of startup. \n5) **Init Containers:** Use an `initContainer` to perform time-consuming tasks (like schema migrations) before the main container starts, shortening the main container's startup time."}
{"question": "You deployed an NGINX Ingress Controller in a private AKS cluster. Ingress is configured with an Azure Internal Load Balancer (ILB). External client traffic reaches the ILB but fails to connect to the backend pods, returning 503/504 errors.", "solution": "The client is successfully reaching the ILB, but the ILB or the Ingress controller cannot reach the backend pods, indicating a CNI, routing, or security group issue between the Ingress controller and the application pods. \n\n1) **Service Endpoints:** Run `kubectl get endpoints <ingress-service-name>`. Ensure the endpoints list the internal Cluster IPs (or CNI-allocated IPs) of the backend pods, and those IPs are correct. \n2) **Ingress Controller Logs:** Check the NGINX Ingress Controller pod logs. Look for 'connection refused' or 'upstream timed out' errors, which confirm the NGINX proxy fails to talk to the pod IPs. \n3) **Network Security Group (NSG):** The NSG associated with the node's subnet must allow traffic from the **Ingress Controller's Node/Pod IP Range** (source) to the **Backend Pods' IP Range** (destination) on the Service's `targetPort`. For Azure CNI, this often means allowing traffic within the subnet or the entire VNet. \n4) **ILB Health Probe:** Verify the ILB's backend health probe is targeting the correct node port (if using NodePort service) or pod IP on the correct path/port. \n5) **Fix:** Manually create an NSG rule allowing inbound traffic to the Node Subnet from the Pod Subnet (or VNet IP range) for the necessary ports."}
{"question": "A `kubectl rollout undo` command fails to revert a Deployment, showing `error: failed to revert: the update of the Deployment is forbidden by the API server`.", "solution": "This specific error usually means an admission controller (like a Validating Webhook or a Gatekeeper policy) is blocking the rollback because the older version of the manifest violates a current security or configuration policy. \n\n1) **Diagnosis:** Run `kubectl describe deployment <deployment-name>` and look at the events after the failed `rollout undo`. The event should contain the specific message from the admission controller that blocked the patch. \n2) **Policy Audit:** Review all active ValidatingWebhookConfigurations and Gatekeeper ConstraintTemplates that apply to the Deployment's namespace. The older, rolling-back version is violating a policy that the currently running version (which was deployed *before* the policy) is compliant with (or was grandfathered in). \n3) **Rollback Strategy:** The `rollout undo` command attempts to **apply** the previous revision's manifest. If that manifest violates a new policy (e.g., mandatory labels, stricter image tags, or securityContext settings), it is rejected. \n4) **Fix:** \n    a) Temporarily disable the violating webhook/policy. \n    b) Run the `kubectl rollout undo`. \n    c) Immediately re-enable the policy and then patch the deployed version to ensure it is compliant with the policy (e.g., adding the missing label or changing the non-compliant field). \n5) **Prevention:** Use **client-side validation** in your GitOps pipeline to ensure all previous manifest revisions are compliant with the current policies."}
{"question": "During a massive scale-out (e.g., after an alert), the cluster Autoscaler (CA) struggles to keep up, creating nodes slowly, and the API server latency spikes, leading to an even slower scale-up loop.", "solution": "The CA is a controller and suffers from API server pressure when it needs to make numerous calls (e.g., to list all nodes, pods) in a short period to determine scaling action. \n\n1) **Diagnosis:** Check the CA logs for 'API server limit exceeded' or frequent retries. Check `kube-apiserver` metrics for high latency on the `LIST` verb for `pods` and `nodes`. \n2) **CA Throttling:** Increase the API server's QPS/burst limits for the CA's service account (if possible via a dedicated APF FlowSchema). \n3) **CA Configuration:** Increase the CA's `--scan-interval` (e.g., from 10s to 30s) to reduce the frequency of heavy resource listing. \n4) **Cloud Provider Throttling:** If running on a cloud (EKS/GKE/AKS), the CA might be hitting the cloud provider's API limits (e.g., EC2, Azure VMSS) when creating too many nodes too quickly. Check the cloud provider logs for throttling errors. \n5) **Mitigation:** Use faster node pool provisioning methods (e.g., GKE Autopilot, EKS Fargate) for burst workloads or configure CA to use multiple node groups simultaneously (`--expander=least-waste`)."}
{"question": "A multi-tenant cluster with strict egress NetworkPolicies uses Istio for service mesh. After enabling Istio's sidecar injection, all pods lose external connectivity, but internal cluster communication is fine. The Istio sidecar is running.", "solution": "Istio, by default, takes over the pod's networking stack, and the egress traffic is routed through the sidecar (Envoy). The policy is likely blocking the sidecar's new path to the external service. \n\n1) **Diagnosis:** Istio routes external traffic via a special `PASSTHROUGH` cluster, which resolves to the external IP. The NetworkPolicy is missing an explicit rule to allow traffic from the Istio sidecar. \n2) **Policy Mismatch:** Standard NetworkPolicies apply to pod network interfaces, not specifically the sidecar process. However, when Istio is injected, the traffic is NAT'd to the sidecar. Your policy must allow traffic from the application pod (or the sidecar's process) to the external IP. \n3) **Fix: Allow Sidecar Egress:** Add a new egress rule to your NetworkPolicy to allow traffic from the Istio-enabled pods to the external IPs or to the Egress Gateway (if configured). Crucially, you must also ensure the policy allows the sidecar to talk to `istiod` (Pilot) for configuration updates. \n4) **Istio Egress Gateway:** The recommended solution is to funnel all external traffic through an Istio Egress Gateway (a dedicated pod with an external IP). Then, adjust the NetworkPolicy to only allow egress from the pods to the **Egress Gateway pod's IP** on the correct port (usually 15001/TCP or 443/TCP) and allow the **Egress Gateway pod's external IP** to the Internet."}
{"question": "A StatefulSet using a custom initContainer to clone a Git repository fails on some nodes with an inconsistent 'Git fatal: detected dubious ownership' error, even though all nodes have the same OS/kernel.", "solution": "This is a security feature in recent Git versions (2.35+) that prevents running Git operations on a repository that is not owned by the user running the command, often seen in containers where the host mounts a volume (which retains host permissions). \n\n1) **Diagnosis:** The `initContainer` is likely running as a non-root user (good practice), but the mounted volume is owned by root or a different host-level UID. \n2) **Permission Fix:** \n    a) **Recommended:** Use the Pod's `securityContext` with `fsGroup` set to the UID/GID that the initContainer will run as. Kubernetes will recursively `chown` the volume to this group, allowing Git access. Set `fsGroupChangePolicy: Always`. \n    b) **Alternative:** In the `initContainer` script, run `git config --global --add safe.directory <repo-path>` to explicitly allow the directory (less secure). \n3) **`hostPath` Caution:** If using `hostPath`, the directory's host permissions are preserved. Ensure the host path is created with the expected permissions. \n4) **Fix:** Set the `securityContext.runAsUser` and `securityContext.fsGroup` in the StatefulSet pod template to match the user the `initContainer` is designed to run as."}
{"question": "A service that relies on a specific kernel feature (e.g., FUSE, a custom network module) fails to start in a GKE Sandbox or EKS Fargate pod with an 'operation not permitted' or 'no such device' error.", "solution": "Sandboxed environments (GKE Sandbox, EKS Fargate) use security-hardened kernels and often deny access to host-level devices, privileged capabilities, and loading of custom kernel modules. \n\n1) **Diagnosis:** Run `kubectl describe pod <pod>` and check the pod's `securityContext`. Check the logs for specific syscall failures or attempts to load a module. \n2) **Sandbox Restrictions:** Fargate/GKE Sandbox runs with a very restricted set of capabilities (no `NET_ADMIN`, no `SYS_MODULE`) and denies `hostPath`, privileged containers, and most sysctls. \n3) **Container Image:** Ensure the container image does not rely on a kernel module that needs to be loaded by the container (it should be pre-loaded on the node). \n4) **Fix:** \n    a) **GKE Sandbox:** If the feature is essential, you must migrate the workload to a standard (non-sandboxed) node pool. \n    b) **EKS Fargate:** Refactor the application to use the networking capabilities provided by the CNI (AWS VPC CNI) without requiring custom kernel modules or privileged access. If the feature is non-negotiable, use standard EKS node groups where you can manage kernel modules and use privileged containers (if necessary and compliant)."}
{"question": "Pods that use projected service account tokens for authentication fail to start with `MountVolume.SetUp failed` after a cluster certificate rotation, showing `x509: certificate signed by unknown authority` in the kubelet logs.", "solution": "The kubelet is responsible for projecting the service account token and its associated CA bundle into the pod. The error means the kubelet is using an outdated or incorrect CA to verify the projected token's issuer (the API server). \n\n1) **Diagnosis:** Check the kubelet's static pod manifest or systemd unit for the `--kubeconfig` file location. Inspect the CA certificate in that kubeconfig file. It likely contains the old cluster CA. \n2) **Kubelet Restart:** Kubelet does not automatically refresh its CA bundle if it's baked into a file. After a control plane certificate rotation, you must update the kubelet's configuration. \n3) **Fix: CA Bundle Update:** \n    a) If using `kubeadm`, run `kubeadm certs renew all` and then `kubeadm init phase kubeconfig all` to update the kubelet's kubeconfig (`/etc/kubernetes/kubelet.conf`). \n    b) Restart the kubelet service (`systemctl restart kubelet`). The kubelet will now use the new CA to verify the API server's identity and correctly project the token. \n4) **Pod Restart:** Force a recreation of the failing pods (`kubectl rollout restart deployment <dep>`) so the kubelet can try the volume mount again with the correct CA bundle."}
{"question": "An NGINX Ingress Controller in a high-traffic environment occasionally returns 400 Bad Request to clients, but only when using HTTP/2, and only during periods of heavy deployment rollouts (churn).", "solution": "This is a complex interaction between the NGINX Ingress Controller's internal configuration state, its upstream (pod) churn, and HTTP/2's connection persistence, which can lead to stale connections. \n\n1) **NGINX Reloads:** Deployment churn causes frequent NGINX configuration reloads. If the reload takes too long, connections (especially persistent HTTP/2 ones) can be reset. Check the NGINX Ingress controller logs for 'reload successful' events and measure the reload time. \n2) **HTTP/2 Stale Connections:** HTTP/2 connections are persistent. If a backend pod is terminated, the client's connection via NGINX might try to hit the dead upstream. \n3) **Fix: Dynamic Configuration:** Enable NGINX Ingress Controller's dynamic configuration features (if available, e.g., `--enable-dynamic-certificates`). This avoids a full reload for simple certificate or endpoint changes. \n4) **HTTP/2 Connection Management:** Tune the NGINX HTTP/2 parameters. Increase `worker-shutdown-timeout` to allow existing connections to gracefully finish. Consider setting `h2-max-requests` lower to force more frequent connection renegotiation. \n5) **Graceful Termination:** Ensure your backend pods have a proper `preStop` hook and `terminationGracePeriodSeconds` to drain active connections before the pod is fully terminated."}
{"question": "After migrating from a community CNI (e.g., Calico) to the cloud provider's managed CNI (e.g., AWS VPC CNI), all `hostNetwork: true` pods lose their network connectivity.", "solution": "CNI plugins manage the network interface for standard pods, but `hostNetwork: true` pods bypass this and use the node's network stack directly. The issue is likely that the cloud CNI is cleaning up or modifying the host's networking in a way that interferes with the `hostNetwork` pod. \n\n1) **Diagnosis:** Run `ip a` inside a failing `hostNetwork` pod and compare it to the node's `ip a` output. Check the `kubelet` logs for CNI-related errors, even though CNI is technically skipped for these pods. \n2) **Firewall/Security Groups:** The `hostNetwork` pod is now using the Node's main IP. Ensure the node's Security Group/Firewall allows the traffic on the application's ports, as the traffic no longer originates from the Pod CIDR. \n3) **IP Tables/Routing:** The previous CNI (e.g., Calico) may have left behind some IP tables or routes that conflict with the cloud CNI's setup. \n4) **Fix:** \n    a) **Node Reboot:** A full node reboot often cleans up any stale CNI artifacts. \n    b) **Refactor:** Avoid `hostNetwork: true` wherever possible. If required, use a dedicated node pool for these workloads and ensure no CNI or network agent DaemonSets interfere with their operation (e.g., by using node selectors/tolerations)."
{"question": "A team uses `kubectl debug` to spawn ephemeral containers for live debugging. They report that the debug shell often drops connections or the ephemeral container is terminated unexpectedly during their session.", "solution": "Ephemeral containers are meant for short-lived diagnostics. They share the namespace of the target container but are subject to the kubelet's lifecycle and potentially resource limits. \n\n1) **Resource Limits:** The ephemeral container shares the cgroups of the sandbox. If the parent pod's cgroups are constrained, the ephemeral container's actions (e.g., running `strace`, dumping logs) might push the cgroup over its limit, leading to an OOMKill of the whole sandbox. \n2) **Connection Stability:** `kubectl debug` uses the same SPDY/HTTP2 tunnel as `kubectl exec`. The connection can drop if the API server-to-kubelet connection is unstable or if the client machine's connection to the API server is intermittent. \n3) **Liveness/Readiness:** If the target pod's liveness probe fails while the ephemeral container is running, the entire pod is terminated, killing the debug session. \n4) **Fix:** \n    a) Use **guaranteed QoS** for pods that need debugging. \n    b) Run the debug session from a stable client/jumpbox. \n    c) Set the ephemeral container's resource requests/limits (if supported by your cluster version) to ensure it has enough resources. \n    d) Check the target pod's logs/events for OOMKills or liveness failures that coincide with the session drop."}
{"question": "After enabling aggressive etcd compaction (`--auto-compaction-retention=1h`), the API server's p99 latency spikes, and controller-manager logs show frequent 'resource version too old' errors.", "solution": "Aggressive compaction removes historical data, which can break the 'watch' mechanism if a controller's watch cache falls too far behind. \n\n1) **Diagnosis:** The 'resource version too old' error is a direct indicator that the controller-manager is watching an etcd key, but the data has been compacted before the controller could process it. \n2) **Watch Cache Size:** The API server has a watch cache. If this cache is too small for the volume of changes, the cache can't keep up, forcing a full relist from etcd, which is slow. Increase `--watch-cache-sizes` (e.g., for `pods`, `deployments`). \n3) **APF Configuration:** Check if the controller-manager is being throttled by APF. Ensure its FlowSchema has sufficient burst and QPS to prevent throttling. \n4) **Compaction Interval:** The 1-hour retention is too aggressive for a busy cluster. Increase the `auto-compaction-retention` to at least 4 hours (e.g., `4h`). \n5) **Fix:** Increase the etcd compaction retention period. Restart the affected controllers (controller-manager, scheduler, custom controllers) to clear their watch caches and force a fresh relist with the new, longer retention window."}
{"question": "A StatefulSet with an `updateStrategy: RollingUpdate` gets stuck during an image update. `kubectl describe sts` shows the new revision has not been created, and the controller is logging 'Forbidden: Pod is not valid for policy'.", "solution": "The StatefulSet controller is being blocked by an admission policy (like PSP, PSA, or Gatekeeper) when attempting to create the new pod for the rolling update. \n\n1) **Diagnosis:** The error 'Pod is not valid for policy' is an admission webhook error. Use `kubectl describe statefulset <sts>` to find the specific error message from the admission controller in the events. \n2) **Policy Mismatch:** The previous version's pod template might have been grandfathered in, but the new pod template (which is created from the new revision) violates a policy that was enabled after the last successful update (e.g., a new `runAsNonRoot` constraint, or a new mandatory label). \n3) **Template Inspection:** Compare the old and new pod templates. The controller is trying to create a new pod with the *new* template. Identify which field in the new template (e.g., a missing security context, a restricted volume type) is causing the policy violation. \n4) **Fix:** \n    a) If the policy is correct, modify the StatefulSet's `spec.template` to comply with the current policies and re-apply. The rollout will then proceed. \n    b) Temporarily disable the violating policy, run the update, and immediately re-enable the policy."}
{"question": "Pods on certain nodes (always the same set of nodes) fail with 'failed to pull image: rpc error: code = NotFound desc = failed to pull and unpack image...: failed to resolve reference: not found' even though the image exists in the registry and other nodes can pull it.", "solution": "The image pulling failure on a subset of nodes, despite the image existing, indicates a localized networking, DNS, or image pull secret issue that is specific to those nodes. \n\n1) **Diagnosis:** SSH into a failing node. Run `crictl pull <image>` to bypass the kubelet and test the container runtime's ability to reach the registry. This often reveals a local DNS or proxy issue. \n2) **Node-Local DNS/Proxy:** Check the node's `/etc/resolv.conf` for the correct DNS server. If the node is behind a proxy, verify the Docker/Containerd proxy configuration (e.g., in `/etc/systemd/system/containerd.service.d/http-proxy.conf`) is correct for the specific nodes. \n3) **Image Pull Secrets:** If a private registry is used, ensure the `imagePullSecrets` are correctly mounted and the kubelet has access to the token on the failing nodes. \n4) **Platform Mismatch:** If the image is multi-arch, the node's architecture might be incorrectly reported to the registry. Run `uname -m` on the nodes to confirm the architecture is correctly reported (e.g., `x86_64` vs `aarch64`). \n5) **Fix:** Correct the proxy configuration or DNS configuration for the specific failing nodes and restart the `kubelet` and `containerd` services to apply the changes."}
{"question": "You enabled a custom scheduler profile with new PodAffinity/AntiAffinity rules. Now, new pods are stuck in Pending, with the scheduler logs showing 'No fit found for pod: the node(s) had preemption candidates that failed to satisfy the new constraints'.", "solution": "The custom scheduling profile is too restrictive, leading to a state where existing, non-compliant pods are preempting the new pods, but the new pods themselves cannot be scheduled because of the very rules that triggered the preemption. \n\n1) **Diagnosis:** Run `kubectl describe pod <pending-pod>` and look at the scheduler's failed predicate messages. The message about preemption candidates means the scheduler *wanted* to move another pod to fit the new one but failed to find a suitable node after the preemption. \n2) **Preemption/AntiAffinity Conflict:** The new `PodAntiAffinity` rule is likely so strict that it prevents the pod from being scheduled anywhere (no node satisfies the `requiredDuringSchedulingIgnoredDuringExecution` rule), or it creates an infinite preemption loop. \n3) **Profile Tune:** Modify the custom scheduler profile. \n    a) Change `requiredDuringSchedulingIgnoredDuringExecution` to `preferredDuringSchedulingIgnoredDuringExecution` to make the rule soft instead of hard. \n    b) Temporarily disable preemption for the affected priority classes. \n4) **Fix:** Relax the `PodAntiAffinity` rule to be less restrictive (e.g., increase the `maxSkew` or change the `topologyKey`). Then, manually cordon and drain the nodes containing the preempted pods to clean up the scheduling state."}
{"question": "An AKS private cluster uses Azure Firewall with FQDN policies. Intermittent outbound connections to a whitelisted SaaS provider fail with a high connection reset rate (RST).", "solution": "The connection resets point to a TCP connection tracking or port exhaustion issue, likely related to how Azure Firewall handles state and SNAT. \n\n1) **Diagnosis (Firewall):** Check the Azure Firewall logs for **SNAT port exhaustion** warnings. The Firewall performs SNAT for all outbound traffic. If you have many connections, the available SNAT ports can be exhausted, leading to random resets. \n2) **Diagnosis (Application):** Use `kubectl exec` into a pod and run `netstat -an | grep TIME_WAIT`. High numbers of `TIME_WAIT` connections indicate the application is opening and closing connections too rapidly, exacerbating SNAT port exhaustion. \n3) **Fix: Egress Optimization:** \n    a) **NAT Gateway:** Attach an Azure NAT Gateway to the AKS subnet. NAT Gateway provides a much larger pool of ephemeral ports and is the standard fix for SNAT exhaustion in AKS. \n    b) **Application Tuning:** Implement connection pooling (e.g., HTTP Keep-Alives) in the application to reuse connections instead of opening/closing new ones for every request. \n    c) **Firewall Tuning:** Increase the TCP idle timeout in the Azure Firewall policy."}
{"question": "A legacy application is deployed as a Deployment with `hostIPC: true`. After a node reboot, the pod restarts but fails to connect to its peer on the same node, which also restarted. They rely on shared memory segments.", "solution": "`hostIPC: true` makes the pod share the host's IPC namespace, including shared memory segments (shmem) and Semaphores. The shared memory segments are often lost or corrupted upon a host reboot or a new container using the same key. \n\n1) **Diagnosis:** Check the application logs for errors like 'shmem segment not found' or 'IPC key conflict'. On the node, use `ipcs -m` (for shmem) and `ipcs -s` (for semaphores) to see the status of the segments. \n2) **Cleanup:** After a clean restart, the application should re-create the necessary IPC segments. If the application failed to clean up the old segment before exiting, manually run `ipcrm` on the node for the stale segment keys. \n3) **Fix: Persistence:** IPC segments are volatile. For shared memory that must persist across container restarts, use a dedicated **`emptyDir` with `medium: Memory`** which is guaranteed to be cleaned up when the pod is deleted, or use the **`shm-size`** volume mount if only shared memory is needed. \n4) **Refactor:** If the application requires true persistence, it should migrate away from shared memory to a proper in-memory store (like Redis) or an NVMe-backed volume."}
{"question": "A GKE Autopilot cluster frequently sees Pods in `CrashLoopBackOff` with 'OOMKilled' despite the pod having generous memory limits and the node having ample free memory. The workload is a JVM application.", "solution": "Autopilot nodes have highly optimized resource management, but JVM OOMKills can happen due to an under-reporting of the container memory limits to the JVM itself, combined with the kernel OOM killer being more aggressive. \n\n1) **Diagnosis:** Check the `dmesg` output on the node for the kernel OOM killer logs. Verify the container's memory limit. \n2) **JVM Awareness:** Older JVMs are not container-aware and read memory from the host's `/proc/meminfo`, not the container's cgroup limits. The JVM process then allocates memory assuming the full host memory is available, leading to the OOMKill when it exceeds the container limit. \n3) **Fix: Container-Aware JVM:** \n    a) Ensure the JVM application is running on Java 8u131+ or Java 11+, and use the flags `-XX:+UseContainerSupport` or `-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap` to make the JVM respect the cgroup limits. \n    b) Explicitly set the JVM heap size (e.g., `-Xmx70%`) relative to the container memory limit. \n4) **Autopilot Tuning:** In Autopilot, you must request **Guaranteed QoS** (requests == limits) to ensure the pod gets the resources and is not subject to burstable throttling, which can exacerbate OOM issues."}
{"question": "A production Kubernetes cluster running 200+ microservices experiences cascading failures during peak traffic. Pods enter CrashLoopBackOff across multiple namespaces, API server latency spikes to 5+ seconds, and etcd shows high disk I/O. The metrics server becomes unresponsive, preventing HPA from scaling. How do you systematically diagnose and recover from this multi-component failure?", "solution": "This scenario indicates a compound failure involving control plane overload and resource exhaustion. Follow this systematic recovery approach:\n\n**Immediate Stabilization (0-5 minutes):**\n1. Identify critical services: Prioritize customer-facing workloads and core infrastructure components.\n2. Implement emergency rate limiting at ingress level to reduce incoming load immediately.\n3. Scale up control plane components if possible: Add API server replicas and increase their resource limits.\n4. Check etcd health: Run `etcdctl endpoint health --cluster` and `etcdctl endpoint status` to identify slow members.\n\n**Root Cause Analysis (5-15 minutes):**\n1. Examine API server metrics: Look for request rate spikes, slow queries, and watch connection counts using Prometheus or built-in metrics.\n2. Analyze etcd performance: Check `etcd_disk_wal_fsync_duration_seconds` and `etcd_disk_backend_commit_duration_seconds`. Values >100ms indicate I/O bottleneck.\n3. Investigate cascading pod failures: Use `kubectl get events --sort-by='.lastTimestamp' -A` to identify the initial failure trigger.\n4. Check for resource quotas: Verify if namespace quotas are blocking pod creation.\n5. Review metrics-server logs: Determine if kubelet certificate issues or network problems are preventing scraping.\n\n**Systematic Recovery (15-45 minutes):**\n1. **etcd Recovery:** If etcd is the bottleneck:\n   - Defragment etcd: `etcdctl defrag --cluster`\n   - Compact old revisions: `etcdctl compact <revision>`\n   - Consider moving etcd to dedicated fast NVMe storage if on shared disks\n   - Increase etcd's IOPS limits and memory allocation\n\n2. **API Server Relief:**\n   - Enable API Priority and Fairness (APF) if not already active\n   - Temporarily disable non-essential admission webhooks\n   - Increase `--max-requests-inflight` and `--max-mutating-requests-inflight`\n   - Review and optimize expensive list operations from controllers\n\n3. **Metrics Server Recovery:**\n   - Restart metrics-server pods: `kubectl rollout restart -n kube-system deployment/metrics-server`\n   - Verify kubelet connectivity: `kubectl get --raw /api/v1/nodes/<node>/proxy/metrics/resource`\n   - Check for certificate expiration or rotation issues\n   - Increase metrics-server replicas and resource allocations\n\n4. **Pod Recovery Strategy:**\n   - Identify and fix the root cause in failing pods (connection pool exhaustion, memory leaks, etc.)\n   - Implement staggered rollout: Don't restart all pods simultaneously\n   - Use PodDisruptionBudgets to control restart velocity\n   - Consider temporarily increasing resource limits to provide headroom\n\n5. **Cascading Failure Prevention:**\n   - Implement circuit breakers in applications to fail fast\n   - Add exponential backoff with jitter for retries\n   - Configure proper readiness and liveness probes with appropriate thresholds\n   - Set up pod anti-affinity to distribute replicas across nodes\n\n**Long-term Prevention:**\n1. Implement control plane monitoring and alerting on etcd latency, API server queue depth, and certificate expiration.\n2. Regular load testing to identify breaking points before production impact.\n3. Implement chaos engineering practices to validate resilience.\n4. Set up multi-region or multi-cluster architecture for critical services.\n5. Create runbooks for common failure scenarios with clear escalation paths.\n6. Review and optimize controller reconciliation loops to reduce API server load.\n7. Implement proper resource requests/limits across all workloads based on actual usage patterns."}
{"question": "After migrating from Docker Swarm to Kubernetes, a legacy application with hardcoded service discovery using Docker's embedded DNS (service.swarm:7000) fails to resolve services. The application cannot be easily modified. Multiple attempts using Kubernetes Services, ExternalName, and CoreDNS rewrites have failed. How do you create a transparent DNS bridge solution?", "solution": "This migration scenario requires a multi-layered DNS solution that preserves legacy behavior while integrating with Kubernetes native service discovery.\n\n**Assessment Phase:**\n1. Document all hardcoded DNS names in the legacy application (e.g., `database.swarm`, `cache.swarm`, `api.swarm`).\n2. Map these names to corresponding Kubernetes Services.\n3. Identify if the application uses SRV records or just A/AAAA records.\n4. Determine if the application runs in multiple namespaces or a single namespace.\n\n**Solution Implementation:**\n\n**Step 1: CoreDNS Custom Configuration**\n\nCreate a custom CoreDNS configuration with rewrite rules:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: coredns-custom\n  namespace: kube-system\ndata:\n  swarm.override: |\n    rewrite stop {\n      name regex (.+)\\.swarm {1}.legacy-apps.svc.cluster.local\n      answer name (.+)\\.legacy-apps\\.svc\\.cluster\\.local {1}.swarm\n    }\n```\n\n**Step 2: Create Kubernetes Services Matching Legacy Names**\n\nFor each legacy service, create a Kubernetes Service:\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: database\n  namespace: legacy-apps\nspec:\n  selector:\n    app: postgres\n  ports:\n  - port: 7000\n    targetPort: 5432\n```\n\n**Step 3: Deploy DNS Proxy Sidecar (Alternative approach)**\n\nIf CoreDNS rewrites don't work, use a sidecar DNS proxy:\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: dns-proxy-config\ndata:\n  dnsmasq.conf: |\n    port=5353\n    address=/database.swarm/database.legacy-apps.svc.cluster.local\n    address=/cache.swarm/redis.legacy-apps.svc.cluster.local\n    server=10.96.0.10#53\n    cache-size=1000\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: legacy-app\nspec:\n  template:\n    spec:\n      dnsPolicy: \"None\"\n      dnsConfig:\n        nameservers:\n          - 127.0.0.1\n        searches:\n          - legacy-apps.svc.cluster.local\n          - svc.cluster.local\n          - cluster.local\n      containers:\n      - name: dns-proxy\n        image: andyshinn/dnsmasq:2.81\n        volumeMounts:\n        - name: config\n          mountPath: /etc/dnsmasq.conf\n          subPath: dnsmasq.conf\n      - name: app\n        image: legacy-app:latest\n      volumes:\n      - name: config\n        configMap:\n          name: dns-proxy-config\n```\n\n**Step 4: Verification and Testing**\n\n1. Test DNS resolution from within pods:\n```bash\nkubectl exec -it <pod> -- nslookup database.swarm\nkubectl exec -it <pod> -- dig database.swarm\nkubectl exec -it <pod> -- curl http://database.swarm:7000/health\n```\n\n2. Verify service connectivity:\n```bash\nkubectl run test --rm -it --image=busybox -- wget -O- http://database.swarm:7000\n```\n\n3. Monitor CoreDNS logs for resolution patterns:\n```bash\nkubectl logs -n kube-system -l k8s-app=kube-dns --tail=100 -f\n```\n\n**Step 5: Handle Edge Cases**\n\n1. **Port Mapping Issues:** If legacy services use non-standard ports, ensure Service definitions map correctly.\n2. **Cross-namespace Access:** Use FQDN format in rewrites: `service.namespace.svc.cluster.local`\n3. **SRV Records:** If the app uses SRV records, create corresponding DNS entries manually.\n4. **DNS Caching:** Clear application-level DNS caches or restart pods after DNS configuration changes.\n\n**Monitoring and Maintenance:**\n\n1. Set up alerts for DNS resolution failures\n2. Monitor CoreDNS query rates and cache hit ratios\n3. Log all `.swarm` domain queries for troubleshooting\n4. Create documentation mapping old names to new services\n5. Plan eventual migration path to native Kubernetes service discovery\n\n**Alternative: Service Mesh Approach**\n\nFor complex scenarios, consider using a service mesh like Istio:\n```yaml\napiVersion: networking.istio.io/v1beta1\nkind: ServiceEntry\nmetadata:\n  name: legacy-swarm-bridge\nspec:\n  hosts:\n  - \"*.swarm\"\n  resolution: DNS\n  endpoints:\n  - address: database.legacy-apps.svc.cluster.local\n```\n\nThis comprehensive approach ensures backward compatibility while gradually modernizing the application infrastructure."}
{"question": "A multi-tenant Kubernetes cluster uses Calico network policies to isolate tenants. After enabling Pod Security Policies and adding new compliance requirements, tenant A's pods can no longer communicate with tenant B's API endpoint despite explicit NetworkPolicy allow rules. Logs show connection timeouts but no policy denials. How do you troubleshoot this cross-tenant networking issue?", "solution": "This scenario involves multiple security layers that can create unexpected interactions. Here's a comprehensive troubleshooting methodology:\n\n**Phase 1: Verify Network Policy Configuration (0-10 minutes)**\n\n1. **Check Policy Existence and Scope:**\n```bash\n# List all NetworkPolicies in both namespaces\nkubectl get networkpolicies -n tenant-a\nkubectl get networkpolicies -n tenant-b\n\n# Examine specific policies\nkubectl describe networkpolicy <policy-name> -n tenant-a\nkubectl describe networkpolicy <policy-name> -n tenant-b\n```\n\n2. **Verify Policy Selectors:**\n```bash\n# Check if pods match the selectors\nkubectl get pods -n tenant-a --show-labels\nkubectl get pods -n tenant-b --show-labels\n\n# Verify namespace labels for namespaceSelector\nkubectl get namespace tenant-a --show-labels\nkubectl get namespace tenant-b --show-labels\n```\n\n3. **Test Policy Evaluation Order:**\n```yaml\n# Ensure ingress rules in tenant B allow traffic from tenant A\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-from-tenant-a\n  namespace: tenant-b\nspec:\n  podSelector:\n    matchLabels:\n      app: api-endpoint\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          tenant: tenant-a\n    - podSelector:\n        matchLabels:\n          app: client\n    ports:\n    - protocol: TCP\n      port: 8080\n```\n\n**Phase 2: Investigate Pod Security Policy Impact (10-20 minutes)**\n\n1. **Check PSP Assignments:**\n```bash\n# Verify which PSP is being used\nkubectl get pod <pod-name> -n tenant-a -o yaml | grep psp\n\n# Check PSP configurations\nkubectl get psp\nkubectl describe psp <psp-name>\n```\n\n2. **Verify Security Context Restrictions:**\n```bash\n# Check if pods have required capabilities\nkubectl get pod <pod-name> -n tenant-a -o jsonpath='{.spec.containers[*].securityContext}'\n\n# Verify if privileged settings block networking\nkubectl get pod <pod-name> -n tenant-a -o yaml | grep -A 10 securityContext\n```\n\n3. **Review Service Account Permissions:**\n```bash\n# Check if service accounts have network access\nkubectl get sa -n tenant-a\nkubectl describe sa <sa-name> -n tenant-a\n\n# Verify RBAC for network operations\nkubectl auth can-i create networkpolicies --as=system:serviceaccount:tenant-a:default\n```\n\n**Phase 3: Deep Packet Analysis (20-35 minutes)**\n\n1. **Deploy Debug Pods:**\n```bash\n# In tenant A namespace\nkubectl run debug-a -n tenant-a --image=nicolaka/netshoot -it --rm\n\n# In tenant B namespace\nkubectl run debug-b -n tenant-b --image=nicolaka/netshoot -it --rm\n```\n\n2. **Test Connectivity Progressively:**\n```bash\n# From debug-a pod:\n# Test DNS resolution\nnslookup api-endpoint.tenant-b.svc.cluster.local\n\n# Test ping (ICMP)\nping <api-endpoint-ip>\n\n# Test TCP connection\ntelnet <api-endpoint-ip> 8080\nnetcat -zv <api-endpoint-ip> 8080\n\n# Trace route\ntraceroute <api-endpoint-ip>\n\n# Check iptables rules\niptables -L -n -v | grep <api-endpoint-ip>\n```\n\n3. **Capture Traffic with tcpdump:**\n```bash\n# On the source pod node\nkubectl debug node/<node-name> -it --image=nicolaka/netshoot\ntcpdump -i any -n host <pod-ip> and port 8080\n\n# Check for dropped packets\nnetstat -s | grep -i drop\n```\n\n**Phase 4: Calico-Specific Diagnostics (35-50 minutes)**\n\n1. **Check Calico Policy Status:**\n```bash\n# Install calicoctl\ncurl -L https://github.com/projectcalico/calico/releases/download/v3.26.0/calicoctl-linux-amd64 -o calicoctl\n\n# Get Calico network policies\ncalicoctl get networkpolicy --all-namespaces\ncalicoctl get globalnetworkpolicy\n\n# Check policy order\ncalicoctl get networkpolicy -n tenant-a -o yaml\n```\n\n2. **Verify Calico Node Status:**\n```bash\n# Check Calico node health\nkubectl get pods -n calico-system\ncalicoctl node status\n\n# Verify BGP peering (if using BGP)\ncalicoctl node diags\n```\n\n3. **Examine Calico Workload Endpoints:**\n```bash\n# Get workload endpoints\ncalicoctl get workloadendpoint -n tenant-a\ncalicoctl get workloadendpoint -n tenant-b\n\n# Check endpoint details\ncalicoctl get workloadendpoint <endpoint-name> -n tenant-a -o yaml\n```\n\n4. **Review Calico Felix Logs:**\n```bash\n# Check for policy programming errors\nkubectl logs -n calico-system -l k8s-app=calico-node --tail=200 | grep -i \"policy\\|deny\\|drop\"\n```\n\n**Phase 5: Common Resolution Patterns**\n\n**Issue 1: Missing Egress Policy**\n```yaml\n# Add explicit egress in tenant A\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-egress-to-tenant-b\n  namespace: tenant-a\nspec:\n  podSelector:\n    matchLabels:\n      app: client\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          tenant: tenant-b\n    ports:\n    - protocol: TCP\n      port: 8080\n  # Allow DNS\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: UDP\n      port: 53\n```\n\n**Issue 2: Incorrect Namespace Labels**\n```bash\n# Fix namespace labels\nkubectl label namespace tenant-a tenant=tenant-a --overwrite\nkubectl label namespace tenant-b tenant=tenant-b --overwrite\n```\n\n**Issue 3: PSP Blocking Network Access**\n```yaml\n# Create a less restrictive PSP for network-intensive pods\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: network-workload\nspec:\n  privileged: false\n  allowPrivilegeEscalation: false\n  requiredDropCapabilities:\n    - ALL\n  allowedCapabilities:\n    - NET_BIND_SERVICE\n    - NET_RAW  # Often needed for network tools\n  volumes:\n    - 'configMap'\n    - 'emptyDir'\n    - 'projected'\n    - 'secret'\n    - 'downwardAPI'\n  hostNetwork: false\n  hostIPC: false\n  hostPID: false\n  runAsUser:\n    rule: 'MustRunAsNonRoot'\n  seLinux:\n    rule: 'RunAsAny'\n  fsGroup:\n    rule: 'RunAsAny'\n```\n\n**Issue 4: DNS Resolution Failure**\n```bash\n# Verify CoreDNS can resolve cross-namespace\nkubectl run -n tenant-a test-dns --image=busybox --rm -it -- nslookup api-endpoint.tenant-b.svc.cluster.local\n\n# Check CoreDNS policy\nkubectl get networkpolicy -n kube-system\n\n# Allow DNS traffic explicitly\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-dns\n  namespace: tenant-a\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: UDP\n      port: 53\n```\n\n**Phase 6: Validation and Monitoring**\n\n1. **Test End-to-End:**\n```bash\n# From tenant-a pod\ncurl -v http://api-endpoint.tenant-b.svc.cluster.local:8080/health\n\n# Check response time\ntime curl http://api-endpoint.tenant-b.svc.cluster.local:8080/health\n```\n\n2. **Set Up Monitoring:**\n```bash\n# Monitor Calico policy hits\ncalicoctl get globalnetworkpolicy -o yaml | grep -A 5 \"doNotTrack: false\"\n\n# Enable Calico policy logging\nkubectl patch felixconfiguration default --type='merge' -p '{\"spec\":{\"flowLogsEnableHostEndpoint\":true}}'\n```\n\n3. **Create Automated Tests:**\n```yaml\n# Periodic connectivity check\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: cross-tenant-connectivity-check\n  namespace: tenant-a\nspec:\n  schedule: \"*/5 * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: test\n            image: curlimages/curl:latest\n            command:\n            - sh\n            - -c\n            - |\n              if curl -s -o /dev/null -w \"%{http_code}\" http://api-endpoint.tenant-b.svc.cluster.local:8080/health | grep -q 200; then\n                echo \"Connectivity OK\"\n              else\n                echo \"Connectivity FAILED\" >&2\n                exit 1\n              fi\n          restartPolicy: Never\n```\n\n**Documentation and Handoff:**\n\n1. Document the root cause and resolution\n2. Update network policy templates with lessons learned\n3. Create runbook for similar issues\n4. Implement alerts for policy-related connectivity failures\n5. Schedule review of all cross-tenant policies quarterly\n\nThis systematic approach ensures all layers are verified and provides a reproducible methodology for similar issues."}
